 # -*- coding: utf-8 -*-
"""abaixe.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RsUIORt1qNzuUX7OAfeYScGkNCI7Q7zt

Abaixe - 'put down'
v.01: (Sin Thank)
    _x_ right now all the reads are first processed by 
    _x_ check input and outputs 
        # the loading and post-loading stats look good - but the RPKM seems to be inflating the numbers severly.
        # recoded 'Make_density.py' v3.0 (Suggest Lecture) to use TPM instead of RPKM
        
    _x_ read depth read in from bed, bedGraph ?
        python scripts/abaixe.py -depth -d depth/DGY1657_depth.tab -v -o depth/DGY1657_abs_depth.p
        ###python scripts/abaixe.py -depth -d depth/DGY1657_depth.tab -r temp_depth.p -v -o temp_depth_r.p
        
v.02 (Meaning Clearance)
    _x_ add genome wide differential expression test  
        python scripts/abaixe.py -exp -i density/ -r depth/_abs_depth.p -o var/
            _x_ make support for TLS, UTR, regions in plots
            _x_ make differential expression represent replicates
            _x_ correct depth of each sample versus the region
    
    _x_ make_fake
        python scripts/abaixe.py -manual -d depth/DGY1657_depth.tab -o depth/DGY1728_depth.tab
        python scripts/abaixe.py -depth -d depth/DGY1728_depth.tab -v -o depth/DGY1728_abs_depth.p
                    
v.03 (Tolerate Mold)
v.04 (Guard Valid)
    _x_ Move away from gene based to location based lookup
        _x_ import reads to a dictionary using chromo and location as keys
            _x_ use modified make_density?
        _x_ use both true reads and normalized reads
        _x_ save as pickles

v.05 (List Mature)
    _x_ Make depth_dict # of reads and uid_depth_dict # of uids
                
    _x_ Make 'reads over region' and 'depth over region' analysis for the process_sam method
        _x_ We need to check that the read normalization is as good or better than the fractional normalization
        _x_ read in gff
        _x_ produce counts
                
    _x_ check the reason why some genes are getting dumped in the parse density log files
            _x_ these are genes absent from the density_dict object
    
v.06 (Hall Disaster)
v.07 (Engineer Axis)
    _x_ redo calculate gene expression to use uid sources
        # currently uses the occupancy output generated by bedtools and gff
        _x_ integrate DNA depth in reads_over_regions
        _x_ verify that reads in tsv are correct.
        
    _x_ improve heatmap plots to enable non-CNV plotting as well

    _x_ with read_depth calculator - why not a heuristic cap, anything over 10 is 10, over 0.2 is 1?
        _x_ maybe best implemented at the plotting level - it does make the other   
    
v0.8 (Location Salon)
    _x_ Enrichment of regulation via command line trends
    _x_ Enrichment of regulation via overlap simulation 
    
v1.0 (Communist Consensus) - Public Beta
    _x_ add in strand switching ("reverse_strand") for sam file read in 
    _x_ Improve depth calculation by masking out "problematic" areas with wacky coverage.
        _x_ low-complexity
        _x_ gag-pol
    _x_ updated to use the experimental object for metadata
        _x_ "reverse_strand"
    _x_ integrate gene_name standardizer
        _x_ currently using "FeatureType_Gene_SGD_Systamtic_Standard.tsv"
            incorporated into the gff_parser
    ___ Replace lm_over_regions with positional analysis
        _x_ minimum region definition requiring 90% hit as a seed - 
            _x_ stich together overlapping regions
        _x_ DNA depth correction
            
        ___ Seperate case handling for RNA, RPF.
            ___ RNA extends or reduces transcript
            ___ RPF extends ORF (N-terminal Isoforms) or pause sites.
            
    ___ Change experiment object to have 'DNA input file' (bedtools genomecov) 
        and rename 'dna_path' to 'Relative DNA file' (output of calculate_depth)
        
    ___ a "range(+1)" issue with dna depth:
        if relative_depth_analysis:
            if nt not in relative_depth_dict[chromo]:
                print('relative_depth_dict[chromo][nt]', chromo, nt)
        
    ___ Future features:
        ___ One to One downsampling:
            Instead of downsampling to the lowest common denominator you downsample to the compared sample
            
        ___ Depth aware sampling:
            Instead of downsampling to the lowest common denomiator of the compared sample you downsample to the 
            expectation of the compared sample given the difference in DNA depth.
    
    ___ Returning to analysis 
    
    
    #RealAnalysis
    ___ Do we find changes in ribosome density in TLS, are these associated with changes in mORF tEff?

    _!_ minor change to expRPF calculation
    ___ update control file / mapping file method
    ___ improve heatmap plots to support all chromosomes
    
    _!_ check why 'YKR103W' DGY1728 DNA read depth is ~1
    _!_ ECM1 with internal TIS, check Nedialkova for rich media
"""


"""
Import 
"""
import numpy as np
import pickle
import pandas as pd
from scipy import stats
import argparse
import re
import random

'''
# Step one: Build experiment object from map file, parse input sam files
python /scratch/ps163/Carolina_03_18_2021/abaixe/abaixe.py -sam -map /scratch/ps163/Carolina_03_18_2021/metadata/map_file.tsv \
    -filter /scratch/ps163/Carolina_03_18_2021/metadata/filter_regions.tab \
    -o /scratch/ps163/Carolina_03_18_2021/pickles/ \
    -experiment /scratch/ps163/Carolina_03_18_2021/pickles/cnv_experiment.p
    
# Step two: Build DNA depth object:
python /scratch/ps163/Carolina_03_18_2021/abaixe/abaixe.py -depth \
    -experiment /scratch/ps163/Carolina_03_18_2021/pickles/cnv_experiment.p \
    -filter /scratch/ps163/Carolina_03_18_2021/metadata/filter_regions.tab
    
# Step three: normalize read depth
python /scratch/ps163/Carolina_03_18_2021/abaixe/abaixe.py \
    -norm \
    -experiment /scratch/ps163/Carolina_03_18_2021/pickles/cnv_experiment.p \
    -o pickles/ 

# Step four: 
python /scratch/ps163/Carolina_03_18_2021/abaixe/abaixe.py -locus_depth \
    --gene_systematic_name_file /scratch/ps163/Carolina_03_18_2021/metadata/FeatureType_Gene_SGD_Systamtic_Standard.tsv \
    -gff /scratch/ps163/Carolina_03_18_2021/ensembl_50/Saccharomyces_cerevisiae.R64-1-1.50.gff3 \
    -feature ensembl \
    -experiment pickles/cnv_experiment.p -o pickles

#Step five
python /scratch/ps163/Carolina_03_18_2021/abaixe/abaixe.py -locus_expression \
    --gene_systematic_name_file /scratch/ps163/Carolina_03_18_2021/metadata/metadata/FeatureType_Gene_SGD_Systamtic_Standard.tsv \
    -gff /scratch/ps163/Carolina_03_18_2021/ensembl_50/Saccharomyces_cerevisiae.R64-1-1.50.gff3 \
    -feature ensembl \
    -experiment pickles/cnv_experiment.p -o pickles/ror
    
#Step six
python abaixe.py -adjust_expression \
    -experiment pickles/cnv_experiment.p -o pickles/ror    

step Seven
python abaixe.py -expression -experiment pickles/cnv_experiment.p \
    -experiment pickles/cnv_experiment.p \
    -o ror_exp_differences
    
step Eight
python /scratch/ps163/Carolina_03_18_2021/scripts/abaixe.py --positional_regions \
    -experiment /scratch/ps163/Carolina_03_18_2021/pickles/cnv_experiment.p \
    -gff /scratch/ps163/Carolina_03_18_2021/ensembl_50/Saccharomyces_cerevisiae.R64-1-1.50.gff3 \
    -feature ensembl \
    -o cnv_exp

python abaixe.py -expression_trends \

arg
    

'''


#file = open('DGY1657_abs_depth.p','rb')
#
#depth = pickle.load(file)
#
#file.close
#
#depth['XI'].keys()

parser = argparse.ArgumentParser()
#python abaixe.py -exp -i ./temp_expression_dict.p -o temp_differences
parser.add_argument('-expression',"--calculate_expression_profile", action='store_true')
parser.add_argument('-i',"--input_abundance_file")
parser.add_argument('-o',"--output_file")

parser.add_argument('-manual',"--manual_depth", action='store_true')

parser.add_argument('-depth',"--calculate_depth", action='store_true')
parser.add_argument('-d',"--input_depth_file")
parser.add_argument('-r',"--relative_depth_file")
parser.add_argument('-round',"--round_DNA_depth")

parser.add_argument('-sam', '--process_sam', action='store_true')
parser.add_argument('-map', '--map_file')
parser.add_argument('-filter', '--filter_regions')
parser.add_argument('-experiment', '--experiment_object')

#normalize parsed sam
# python abaixe.py -norm -experiment pickles/cnv_experiment.p -o pickles/ 
parser.add_argument('-norm', '--normalize_reads', action='store_true')

#reads_over_regions
parser.add_argument('-ror', '--reads_over_regions', action='store_true')
parser.add_argument('-gsnf', '--gene_systematic_name_file')
parser.add_argument('-locus_depth', '--locus_depth', action='store_true')
parser.add_argument('-locus_expression', '--locus_expression', action='store_true')
parser.add_argument('-adjust_expression','--adjust_expression', action='store_true')

parser.add_argument('-gff', '--gff_file_name')
parser.add_argument('-bed', '--bed_file_name')
parser.add_argument('-feature', '--feature_name')

parser.add_argument('-dor', '--depths_over_regions', action='store_true')

parser.add_argument('-pr', '--positional_regions', action='store_true')

#parser.add_argument('-v',"--verbose", action='store_true')

# python abaixe.py -norm -experiment pickles/cnv_experiment.p -o pickles/ 
parser.add_argument('-plot', '--plot', action='store_true')

parser.add_argument('-trends', '--expression_trends', action='store_true')

args = parser.parse_args()

'''
set globals
'''
density_dict = {}
coord_dict = {}
relative_depth_dict = {}
dna_depth = False

chromo_standardizer = {"NC_001133.9":"I", "NC_001134.8":"II", "NC_001135.5":"III", 
                       "NC_001136.10":"IV", "NC_001137.3":"V", "NC_001138.5":"VI", 
                       "NC_001139.9":"VII", "NC_001140.6":"VIII", "NC_001141.2":"IX", 
                       "NC_001142.9":"X", "NC_001143.9":"XI", "NC_001144.5":"XII", 
                       "NC_001145.3":"XIII", "NC_001146.8":"XIV", "NC_001147.6":"XV", 
                       "NC_001148.4":"XVI", "NC_001224.1":"MT",
                       "chrI":"I", "chrII":"II", "chrIII":"III", 
                       "chrIV":"IV", "chrV":"V", "chrVI":"VI", 
                       "chrVII":"VII", "chrVIII":"VIII", "chrIX":"IX", 
                       "chrX":"X", "chrXI":"XI", "chrXII":"XII", 
                       "chrXIII":"XIII", "chrXIV":"XIV", "chrXV":"XV", 
                       "chrXVI":"XVI", "chrMT":"MT",
                       "ChrI":"I", "ChrII":"II", "ChrIII":"III", 
                       "ChrIV":"IV", "ChrV":"V", "ChrVI":"VI", 
                       "ChrVII":"VII", "ChrVIII":"VIII", "ChrIX":"IX", 
                       "ChrX":"X", "ChrXI":"XI", "ChrXII":"XII", 
                       "ChrXIII":"XIII", "ChrXIV":"XIV", "ChrXV":"XV", 
                       "ChrXVI":"XVI", "ChrMT":"MT",
                       "chrmt":"MT",
                       "I":"I", "II":"II", "III":"III", 
                       "IV":"IV", "V":"V", "VI":"VI", 
                       "VII":"VII", "VIII":"VIII", "IX":"IX", 
                       "X":"X", "XI":"XI", "XII":"XII", 
                       "XIII":"XIII", "XIV":"XIV", "XV":"XV", 
                       "XVI":"XVI", "Mito":"MT",}

chromo_set = ['I','II','III','IV','V', 'VI','VII', 'VIII', 'IX', 'X', 'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI']

#chromo_set = ['VIII']

if args.round_DNA_depth:
    depth_round = int(args.round_DNA_depth)
else:
    depth_round = 0

def check_for_name(xname):
    global density_dict

    for gene in density_dict:
        if xname in density_dict[gene]:
            return(True)
        else:
            return(False)
            
def gene_systemitizer(gene_lookup_name, remove_if=True):
    
    gene_lookup_file = open(gene_lookup_name)
    
    filter_set = set(['Dubious'])
    
    #SGD_Primary_DBID	Systematic	Standard	Status
    gene_standard = {}
    
    for line in gene_lookup_file:
        if line[0] != '#':
            line = line.strip()
            process = True

            sgd, systematic, standard, status = line.split('\t')
            status = status.strip()

            if remove_if:                
                if status in filter_set:
                    process = False
            
            if process:
                if standard == "''":
                    standard = sgd
                
                if sgd not in gene_standard:
                    gene_standard[sgd] = systematic
                else:
                    print('sgd name collision', line)
                                
                if systematic not in gene_standard:
                    gene_standard[systematic] = systematic
                else:
                    print('systematic name collision', line) 
                
                if standard not in gene_standard:
                    gene_standard[standard] = systematic
                else:
                    print('standard name collision', line)
                
    return(gene_standard)
            

def get_genome_depth(infile_name, outfile_name, regions_to_filter, relative_depth_analysis, relative_depth_file):
    #infile = open("DGY1657_depth.tab")
    
    #experiment_object_name = open(args.experiment_object)
    
    infile = open(infile_name)
    
    genome_list = []
    chromo_deets_dict = {}
    ct_dict = {}
    cn_dict = {}
    
    for line in infile:
        if line[0]!='#':
        
            chromo = chromo_standardizer[line.split('\t')[0]]
            nt = int(line.split('\t')[1])
            
            process = True
            
            if chromo in regions_to_filter:
                if (nt in regions_to_filter[chromo]['+']) or (nt in regions_to_filter[chromo]['-']):
                    process = False
            
#            #filter mitochondria
#            if chromo == 'MT':
#                process = False
#            
#            #filter rDNA
#            if chromo == 'XII':
#                if (nt > 451410) and (nt < 489500):
#                    process = False
            
            if process:
                count = int(line.split('\t')[2])
                
                if chromo not in ct_dict:
                    print('processing ', chromo)
                    ct_dict[chromo] = {}

                ct_dict[chromo][nt] = count
                    
                if chromo not in chromo_deets_dict:
                    chromo_deets_dict[chromo] = {'total':[], 'nt_list':[], 'min':1, 'max':0}
                    
                chromo_deets_dict[chromo]['total'].append(count)  
                chromo_deets_dict[chromo]['nt_list'].append(nt)

                genome_list.append(count)
                 
    infile.close()
    
    for chromo in chromo_deets_dict:
        chromo_deets_dict[chromo]['min'] = min(chromo_deets_dict[chromo]['nt_list'])
        chromo_deets_dict[chromo]['max'] = max(chromo_deets_dict[chromo]['nt_list'])   
                
    for chromo in ct_dict:
        chromo_deets_dict[chromo]['median'] = np.median(chromo_deets_dict[chromo]['total'])
        chromo_deets_dict[chromo]['mean'] = np.mean(chromo_deets_dict[chromo]['total'])
        chromo_deets_dict[chromo]['std'] = np.std(chromo_deets_dict[chromo]['total'])
    
    genome_median = np.median(genome_list)
    
    if relative_depth_analysis:
        file = open(relative_depth_file,'rb')
        relative_depth_dict = pickle.load(file)
        file.close()
    
    for chromo in ct_dict:
        if chromo not in cn_dict:
            cn_dict[chromo] = {}
        
        for nt in ct_dict[chromo]:
            if not relative_depth_analysis:
                cn_dict[chromo][nt] = ct_dict[chromo][nt]/genome_median
            
            if relative_depth_analysis:
                if nt not in relative_depth_dict[chromo]:
                    print('relative_depth_dict[chromo][nt]', chromo, nt)
                else:    
                    if relative_depth_dict[chromo][nt] != 0:
                        cn_dict[chromo][nt] = (ct_dict[chromo][nt]/genome_median)/relative_depth_dict[chromo][nt]
                    else:
                        cn_dict[chromo][nt] = (ct_dict[chromo][nt]/genome_median)
    
    #if verbose: bedgraph 
    #if args.verbose:
    if not relative_depth_analysis:
        outfile = open(outfile_name.split('.')[0] + '.log', 'w')
        
        outline = ('Sample:\t{}\nRelative to:\tNA\nMedian depth:\t{}\tMean depth:\t{}\tStandard deviation:\t{}\n#===#\n').format(outfile_name, 
genome_median, np.mean(genome_list), np.std(genome_list))
        outfile.write(outline)

    if relative_depth_analysis:
        outfile = open(outfile_name.split('.')[0] + '_relative.log', 'w')
    
        outline = ('Sample:\t{}\nRelative to:\t{}\nMedian depth:\t{}\tMean depth:\t{}\tStandard deviation:\t{}\n#===#\n').format(outfile_name, 
relative_depth_file, genome_median, np.mean(genome_list), np.std(genome_list))
        outfile.write(outline)
    
    for chromo in chromo_deets_dict:      
        outline = ('Chromo:\t{chromo}\t{cmin}:{cmax}\nMedian depth:\t{cmedian}\tMean depth:\t{cmean}'
                   '\tStandard deviation:\t{cstd}\nMinimum depth:\t{mind}'
                   '\tMaximum depth:\t{maxd}\n').format(chromo = chromo,
                  cmin = chromo_deets_dict[chromo]['min'], cmax = chromo_deets_dict[chromo]['max'],
                  cmedian = chromo_deets_dict[chromo]['median'], cmean = chromo_deets_dict[chromo]['mean'], 
                  cstd = chromo_deets_dict[chromo]['std'],
                  mind = min(chromo_deets_dict[chromo]['total']), maxd = max(chromo_deets_dict[chromo]['total']))
        outfile.write(outline)

    outfile.close()
    
    #TODO fix this - the otuput doesn't include all the chromosomes or sites
    outfile = open(outfile_name.split('.')[0] + '_relative_depth.bedgraph', 'w')
    #outfile = open('_relative_depth.bedgraph', 'w')
    
    for chromo in cn_dict:
        region = {"start":'null', 'stop':'null', "val":0}
        
        for nt in range(chromo_deets_dict[chromo]['min'], (chromo_deets_dict[chromo]['max'])+1):
            
            if nt in cn_dict[chromo]:
                if region["start"] == 'null':
                    region["start"] = nt
                    region["val"] = round(cn_dict[chromo][nt],1)
                                                                
                if region["val"] != round(cn_dict[chromo][nt],1) or (nt+1 > (chromo_deets_dict[chromo]['max'])):
                    outline = ('{}\t{}\t{}\t{}\n').format(chromo, region["start"], region["stop"]+1, region["val"])
                    #print(outline)
                    outfile.write(outline)
                    region["start"] = nt
                    region["stop"] = nt
                    region["val"] = round(cn_dict[chromo][nt],1)

                else:
                    region["stop"] = nt
                    
    outfile.close()
    
    pickle_name = ('{}').format(outfile_name)
    pickle.dump(cn_dict, open(pickle_name, 'wb'))
    
    print('Completed ', pickle_name)
        
    return()

def pull_counts(zname, gene_list):

    global relative_depth_dict
    
    gene_val = {'total':[]}
    
    #if check_for_name(zname):
    for gene in density_dict:
        if zname in density_dict[gene]:
            gene_count = density_dict[gene][zname]
        else:
            gene_count = 0
            
        #TODO - this is acting as a limit to a full genome search
        #TODO - remove, replace
        if gene in gene_list:
            gene_val[gene] = gene_count
        else:
            gene_val['total'].append(gene_count)
                        
    for gene in gene_list:
        if gene not in density_dict:
            gene_val[gene] = 0
            
    return(gene_val)
    
def parse_sig(gene, pval, eff, val_dict):
    if (pval <= 0.05):
        if (eff <= 0.5):
            val_dict['low'].add(gene)
            #1/0
        if (eff >= 1.5):
            val_dict['high'].add(gene)
            #1/0
            
    return(val_dict)
    
def print_sig(sig_dict, readis, outfile):
    for istype in sig_dict:
        for gene in sig_dict[istype]:
            outline = ('{}\t{}\t{}\n').format(readis, istype, gene)
            outfile.write(outline)
            
def obs_exp_fet_test(obs_1, obs_2, exp_1, exp_2, correction):
    if (obs_1 + exp_1) > 20 and (obs_2 + exp_2) > 20:
        _no, pval = stats.fisher_exact([[obs_1, exp_1], [obs_2, exp_2]])
        pval *= correction
        eff = (obs_1 / max(exp_1, 1))/(max(obs_2, 1) / max(exp_2, 1))
    else:
        pval = 1
        eff = 1
    return(pval, eff)
    
'''
'''
def deep_enough(runmode, relative_DNA_depth):
    if runmode == 'CNN' or runmode == 'genome':
        if relative_DNA_depth == 1:
            return(True)
        else:
            return(False)
            
    if runmode == 'CNV':
        if relative_DNA_depth > 1:
            return(True)
        else:
            return(False)
    return(False)
    
sample_dict = {}

def parse_tables(sample, infile_name, runmode):
    global sample_dict
    
    gene_set = set()
    RNA_dict = {'down':[], 'up':[]}
    RPF_dict = {'down':[], 'up':[]}
    tEff_dict = {'down':[], 'up':[]}
    buffer_dict = {'down':[], 'up':[]}
    amp_dict = {'down':[], 'up':[]}
    
    infile = open(infile_name)
    
    for line in infile:
        #gene	relative_DNA_depth	obs_RPF_1	obs_RPF_2	obs_RNA_1	
        #obs_RNA_2	ans_RPF_1	ans_RPF_2	ans_RNA_1	ans_RNA_2	exp_RPF_1	
        #exp_RPF_2	exp_RNA_1	exp_RNA_2	obs_1_tEff	obs_2_tEff	exp_1_tEff	
        #exp_2_tEff	obs_mean_RPF	obs_mean_RNA	exp_mean_RPF	exp_mean_RNA	
        #RPF_pval	RPF_eff	RNA_pval	RNA_eff	tEff_pval	tEff_eff	RNA_sig	RPF_sig	tEff_sig	
        if 'gene' not in line.split('\t')[0]:
            gene = line.split('\t')[0]
            relative_DNA_depth = float(line.split('\t')[1])
            rna = float(line.split('\t')[25])
            rpf = float(line.split('\t')[23])
            teff = float(line.split('\t')[27])
            
            
            if deep_enough(runmode, relative_DNA_depth):
                gene_set.add(gene)
                
                if line.split('\t')[28] == 'True':
                    if rna > 1:
                        RNA_dict['up'].append(gene)
                    else:
                        RNA_dict['down'].append(gene)
            
                if line.split('\t')[29] == 'True':
                    if rpf > 1:
                        RPF_dict['up'].append(gene)
                    else:
                        RPF_dict['down'].append(gene)
                        
                if 'True' in line.split('\t')[30]:
                    if teff > 1:
                        tEff_dict['up'].append(gene)
                    else:
                        tEff_dict['down'].append(gene)
                        
                if ('True' in line.split('\t')[30]):
                    if (rna > 1.2) and (rpf < (rna - rna*.2)):                
                        buffer_dict['down'].append(gene)
                    if (rna < 0.8) and (rpf > (rna + rna*.2)):
                        buffer_dict['up'].append(gene)
                        
                if ('True' in line.split('\t')[30]):
                    if (rna > 1.2) and (rpf > (1.2 + rna*.2)):                
                        amp_dict['up'].append(gene)
                    if (rna < 0.8) and (rpf < (0.8 - rna*.2)):
                        amp_dict['down'].append(gene)
            
    outline = ('{}\n'
               'runmode:_{}_gene: _{}\n'
               'RNA: down:_{}_up:_{}\n'
               'RPF: down:_{}_up:_{}\n'
               'tEff: down:_{}_up:_{}\n'
               'buff: down:_{}_up:_{}\n'
               'amp: down:_{}_up:_{}\n').format(sample,
                           runmode, len(gene_set),
                       len(RNA_dict['down']), len(RNA_dict['up']),
                       len(RPF_dict['down']), len(RPF_dict['up']),
                       len(tEff_dict['down']), len(tEff_dict['up']),
                       len(buffer_dict['down']), len(buffer_dict['up']),
                       len(amp_dict['down']), len(amp_dict['up']))       
    print(outline)
    
    infile.close()
    
    sample_dict[sample] = {'rna':RNA_dict, 'rpf':RPF_dict, 'teff':tEff_dict, 'buff':buffer_dict, 'amp':amp_dict, 'ct': len(gene_set)}

'''
#TODO proper command argument here
if False:
    sample_list = ['1726', '1728', '1735', '1741', '1743']
    for sample in sample_list:
        print(sample)
    
        genome_sample = ('mORF_rel_CNN_{}v1657').format(sample)
        CNV_sample = ('mORF_rel_CNV_{}v1657').format(sample)
        
        infile = ('C:/Gresham/Project_Carolino/var_rerun/{}.tab').format(genome_sample)
        parse_tables(genome_sample, infile, 'genome')
        
        infile = ('C:/Gresham/Project_Carolino/var_rerun/{}.tab').format(CNV_sample)
        parse_tables(CNV_sample, infile, 'CNN')
        parse_tables(CNV_sample, infile, 'CNV')
    
        #sample_a = 'mORF_rel_CNV_1743v1657'
        x=len(sample_dict[CNV_sample]['buff']['down'])
        y=len(sample_dict[CNV_sample]['buff']['up'])
        z=sample_dict[CNV_sample]['ct']
        
        #sample_b='mORF_rel_CNN_1743v1657'
        a=len(sample_dict[genome_sample]['buff']['down'])
        b=len(sample_dict[genome_sample]['buff']['up'])
        c=sample_dict[genome_sample]['ct']
    
        uppval, upeff = obs_exp_fet_test(y, z, b, c, 1)
        dnpval, dneff = obs_exp_fet_test(x, z, a, c, 1)
        
        print(x, y, z, a, b, c)
        outline = ("{}_{}_{}_{}_{}\n").format(sample, uppval, upeff, dnpval, dneff)
        print(outline)
        
        totpval, toteff = obs_exp_fet_test((x+y), z, (a+b), c, 1)
        #dnpval, dneff = obs_exp_fet_test(x, z, a, c, 1)
        
        print(x, y, z, a, b, c)
        outline = ("{}_{}_{}\n").format(sample, totpval, toteff,)
        print(outline)
        
'''

def define_region(gene, line, gene_dict):
    
    chromo = chromo_standardizer[line.split('\t')[0]]
        
    sign = line.split('\t')[6]
    left = int(line.split('\t')[3])
    right = int(line.split('\t')[4])
    
    if gene not in gene_dict:
        gene_dict[gene] = {'min': left, 'max': right, 'chromo':chromo, 'sign':sign}
        
    if left < gene_dict[gene]['min']:
        gene_dict[gene]['min'] = left
        
    if right > gene_dict[gene]['max']:
        gene_dict[gene]['max'] = right
        
    return(gene_dict)
    
def parse_bed_for_feature(bedfile_name):
    # parse gff to build out tls, morf, and utr for each gene
    # first read in min max of each CDS
    
    global chromo_set
    gene_dict = {}
    #TODO finish filter handling
    locus_to_name = {}
    chromo_to_locus = {}
        
    bedfile = open(bedfile_name)
       
    print('Processing bed file ...')
    for line in bedfile:
        if line[0] != '#':
            #chrXVI	593068	593110	YPR016C.593110	29	-
            line = line.strip()
            chromo, left, right, feature, score, sign = line.split('\t')
            
            left = int(left)
            right = int(right)
    
            if feature not in gene_dict:
                gene_dict[feature] = {'min': left, 'max': right, 'chromo':chromo, 'sign':sign}
        
            if left < gene_dict[feature]['min']:
                gene_dict[feature]['min'] = left
                
            if right > gene_dict[feature]['max']:
                gene_dict[feature]['max'] = right
                            
    bedfile.close()
                
    #move into locus format
    for feature in gene_dict:
        chromo = gene_dict[feature]['chromo']
        start = gene_dict[feature]['min']
        stop = gene_dict[feature]['max']
        sign = gene_dict[feature]['sign']
        
        locus = [chromo, start, stop, sign]
        
        if chromo not in chromo_to_locus:
            chromo_to_locus[chromo] = [locus]
        else:
            chromo_to_locus[chromo].append(locus)   
            
        locus = ('{}:{}-{},{}').format(chromo, start, stop, sign)

        if locus not in locus_to_name:
            locus_to_name[locus] = set()
            locus_to_name[locus].add(feature)
            
        else:
            locus_to_name[locus].add(feature)

    return(locus_to_name, chromo_to_locus)

def parse_gff_for_feature(gfffile_name, feature_name='CDS'):
    # parse gff to build out tls, morf, and utr for each gene
    # first read in min max of each CDS
    if args.gene_systematic_name_file:
        gene_systematic_name_file = args.gene_systematic_name_file
    else:
        #TODO fix this
        gene_systematic_name_file = 'metadata/FeatureType_Gene_SGD_Systamtic_Standard.tsv'
        
    gene_lookup_name = (gene_systematic_name_file)
    gene_system = gene_systemitizer(gene_lookup_name, True)
    
    global chromo_set
    gene_dict = {}
    #TODO finish filter handling
    locus_to_name = {}
    chromo_to_locus = {}
        
    gfffile = open(gfffile_name)
       
    print('Processing gff file ...')
    for line in gfffile:
        if line[0] != '#':
            line = line.strip()
            
            if (feature_name.lower() == 'ensembl') or (feature_name.lower() == 'r64') or (feature_name.lower() == 'sgd'):
                #I	sgd	CDS	335	649	.	+	0	ID=CDS:YAL069W;Parent=transcript:YAL069W_mRNA;protein_id=YAL069W
                if line.split('\t')[2] == 'CDS':
                    if 'ID=CDS:' in line.split('\t')[8]:
                        gene = line.split('\t')[8].split('ID=CDS:')[1].split(';')[0]
                    else:
                        print(line)
                        1/0
                        #gene = line.split('\t')[8].split('SGD:')[1].split(',')[0].split(';')[0]
                        
                    if gene in gene_system:
                        gene = gene_system[gene]
                        
                    define_region(gene, line, gene_dict)
                    
            if feature_name == 'gene':
                # ___ temp filter
                if (line.split('\t')[2] == 'three_prime_UTR') or (line.split('\t')[2] == 'five_prime_UTR'):
                    gene = line.split('\t')[8].split('=')[1].split('_')[0]
                    
                    if gene in gene_system:
                        gene = gene_system[gene]
                    
                    define_region(gene, line, gene_dict)
                    
                if line.split('\t')[2] == 'gene':
                    gene = line.split('\t')[8].split('=')[1]
                    
                    if gene in gene_system:
                        gene = gene_system[gene]
                    
                    define_region(gene, line, gene_dict)
                    
            if feature_name == 'CDS':
                if line.split('\t')[2] == 'CDS':
                    
                    if 'gene=' in line.split('\t')[8]:
                        gene = line.split('\t')[8].split('gene=')[1].split(';')[0]
                    else:
                        gene = line.split('\t')[8].split('SGD:')[1].split(',')[0].split(';')[0]
                        
                    if gene in gene_system:
                        gene = gene_system[gene]
                        
                    define_region(gene, line, gene_dict)
                
    gfffile.close()
                
    #move into locus format
    for gene in gene_dict:
        chromo = gene_dict[gene]['chromo']
        start = gene_dict[gene]['min']
        stop = gene_dict[gene]['max']
        sign = gene_dict[gene]['sign']
        
        locus = [chromo, start, stop, sign]
        
                                    
        if chromo not in chromo_to_locus:
            chromo_to_locus[chromo] = [locus]
        else:
            chromo_to_locus[chromo].append(locus)   
            
        locus = ('{}:{}-{},{}').format(chromo, start, stop, sign)

        if locus not in locus_to_name:
            locus_to_name[locus] = set()
            locus_to_name[locus].add(gene)
            
        else:
            locus_to_name[locus].add(gene)

    return(locus_to_name, chromo_to_locus)
    
def parse_bed_for_feature(bedfile_name, feature_name='CDS'):
    pass
    return()

#def parse_gff_for_regions(gfffile_name, feature_name='CDS', runmode='mORF', feature_filter=False):
#    global chromo_set
#    
#    #TODO finish filter handling
#    locus_to_name = {}
#    chromo_to_locus = {}
#    
#    gfffile = open(gfffile_name)
#       
#    print('Processing gff file ...')
#    for line in gfffile:
#        if line[0] != '#':
#            line = line.strip()
#            
#            # ___ temp filter
#
#            if feature_name in line.split('\t')[2]:
#                chromo = line.split('\t')[0].split('chr')[1]
#                #chromo = line.split('\t')[0]
#                
#                if chromo in chromo_set:
#                    sign = line.split('\t')[6]
#                    
#                    if runmode == 'mORF':
#                        start = int(line.split('\t')[3])
#                        stop = int(line.split('\t')[4])
#                        
#                    if runmode == 'TIS':                        
#                        if sign == '+':
#                            start = int(line.split('\t')[3])
#                            stop = start+2     
#                        if sign == '-':
#                            stop = int(line.split('\t')[4])
#                            start = stop-2
#
#                    locus = [chromo, start, stop, sign]
#                    name = line.split('\t')[8]
#                                                
#                    if chromo not in chromo_to_locus:
#                        chromo_to_locus[chromo] = [locus]
#                        
#                    else:
#                        chromo_to_locus[chromo].append(locus)   
#                        
#                    locus = ('{}:{}-{},{}').format(chromo, start, stop, sign)
#    
#                    if locus not in locus_to_name:
#                        locus_to_name[locus] = set()
#                        locus_to_name[locus].add(name)
#                        
#                    else:
#                        locus_to_name[locus].add(name)
#                                
#    gfffile.close()
#    return(locus_to_name, chromo_to_locus)
    
def obs_exp_bet_test(obs, exp, correction):
    if (obs + exp) > 20:
        pval = stats.binom_test([obs, exp])*correction
        eff = (obs/max(exp,1))
    else:
        pval = 1
        eff = 1
    return(pval, eff)
       
def expression_level_criteria(obs_1, obs_2, exp_1, exp_2, correction):
    process = False
    
    obs_mean = np.mean([obs_1, obs_2])
    obs_std = np.std([obs_1, obs_2])
    
    exp_mean = np.mean([exp_1, exp_2])
    exp_std = np.std([exp_1, exp_2])
    
    l_1_pval, l_1_eff = obs_exp_bet_test(obs_1, exp_1, correction)
                        
    l_2_pval, l_2_eff = obs_exp_bet_test(obs_2, exp_2, correction)
    
    l_eff = np.mean([l_1_eff, l_2_eff])
    l_pval = np.mean([l_1_pval, l_2_pval])
    
    if ((l_1_pval <= 0.05) and (l_2_pval <= 0.05)):
        #test that difference between samples in less than the variance between replicates 
        if (abs(obs_mean - exp_mean) >= abs(obs_std - exp_std)):
            #test for same direction of change
            if ((l_1_eff < 1) and (l_2_eff < 1)) or ((l_1_eff >= 1) and (l_2_eff >= 1)):            
                 process = True
                 
    return(obs_mean, exp_mean, l_eff, l_pval, process)
    
def expression_2_level_criteria(orpf_1, orna_1, orpf_2, orna_2, erpf_1, erna_1, erpf_2, erna_2, correction):
    process = False
    tEff_eff = 1
    tEff_1_pval = 1 
    tEff_2_pval = 1
    
    otef_1 = (orpf_1 / max(orna_1,1))
    otef_2 = (orpf_2 / max(orna_2,1))
    
    #TODO - why is this switched?
    etef_2 = (erpf_1 / max(erna_1,1))
    etef_1 = (erpf_2 / max(erna_2,1))
    
#    otef_1 = (orpf_1 / max(orna_1,1))
#    otef_2 = (orpf_2 / max(orna_2,1))
#    
#    etef_1 = (erpf_1 / max(erna_1,1))
#    etef_2 = (erpf_2 / max(erna_2,1))
    
    if etef_1 != 0:
        tEff_1_eff = otef_1/etef_1
    else:
        tEff_1_eff = otef_1
        
    if etef_2 !=0:
        tEff_2_eff = otef_2/etef_2
    else:
        tEff_2_eff = otef_2
        
    tEff_eff = np.mean([tEff_1_eff, tEff_2_eff])
        
    if ((((orpf_1 + orna_1) > 20 and ((erpf_1 + erna_1)) > 20)) 
        and (((orpf_2 + orna_2) > 20 and ((erpf_2 + erna_2)) > 20))):
        
        _no, tEff_1_pval = stats.fisher_exact([[orpf_1, orna_1], [erpf_1, erna_1]])
        #print(tEff_1_pval)
        tEff_1_pval *= correction
        
        #nested inside to prevent false runs, it must match both criteria for tEff_eff and tEff_pval to change
        if (tEff_1_pval <= 0.05):
            _no, tEff_2_pval = stats.fisher_exact([[orpf_2, orna_2], [erpf_2, erna_2]])
            #print(tEff_2_pval)
            tEff_2_pval *= correction
            
            if (tEff_2_pval <= 0.05):       
                #test that difference between samples in less than the variance between replicates
                otef_mean = np.mean([otef_1, otef_2])
                otef_std = np.std([otef_1, otef_2])

                etef_mean = np.mean([etef_1, etef_2])
                etef_std = np.std([etef_1, etef_2])

                if (abs(otef_mean - etef_mean) >= abs(otef_std - etef_std)):
                    process = True
                        
    tEff_pval = np.mean([tEff_1_pval, tEff_2_pval])
                 
    return(otef_1, otef_2, etef_1, etef_2, tEff_eff, tEff_pval, process)
    
#def stats_on_counts(strain, site, observed_RPF_1, observed_RPF_2, observed_RNA_1, 
#                    observed_RNA_2, expected_RPF_1, expected_RPF_2, expected_RNA_1, expected_RNA_2, gene_list, outname):
#    global density_dict
#    global depth_round
#    
#    outfile_name = ('{}{}_{}').format(args.output_file, site, outname)
#    outfile = open(outfile_name, 'w')
#    
#    outfile_sig_name = ('{}{}_{}_sig.{}').format(args.output_file, site, outname.split('.')[0], outname.split('.')[1])
#    outfile_sig = open(outfile_sig_name, 'w')
#    
#    outfile_call_name = ('{}{}_{}_call.log').format(args.output_file, site, outname.split('.')[0], outname.split('.')[1])
#    outfile_call = open(outfile_call_name, 'w')
#    
#    sig_RNA = {'low':set(), 'high':set()}
#    sig_RPF = {'low':set(), 'high':set()}
#    sig_tEff = {'low':set(), 'high':set()}
#    
#    mean_RNA_list = []
#    mean_RPF_list = []
#    mean_tEff_list =[]
#    
#    header = ('gene\trelative_DNA_depth\t'
#              'obs_RPF_1\tobs_RPF_2\tobs_RNA_1\tobs_RNA_2\t'
#              'ans_RPF_1\tans_RPF_2\tans_RNA_1\tans_RNA_2\t'
#              'exp_RPF_1\texp_RPF_2\texp_RNA_1\texp_RNA_2\t'
#              'obs_1_tEff\tobs_2_tEff\texp_1_tEff\texp_2_tEff\t'
#              'obs_mean_RPF\tobs_mean_RNA\texp_mean_RPF\texp_mean_RNA\t'
#              'RPF_pval\tRPF_eff\tRNA_pval\tRNA_eff\ttEff_pval\ttEff_eff\t'
#              'RNA_sig\tRPF_sig\ttEff_sig\n')
#    
##    '{gene}\t{DNA}\t'
##    '{oRPF1}\t{oRPF2}\t{oRNA1}\t{oRNA2}\t'
##    '{aRPF1}\t{aRPF2}\t{aRNA1}\t{aRNA2}\t'
##    '{eRPF1}\t{eRPF2}\t{eRNA1}\t{eRNA2}\t'
##    '{oRPF}\t{oRNA}\t{eRPF}\t{eRNA}\t'
##    '{RPF_pval}\t{RPF_eff}\t{RNA_pval}\t{RNA_eff}\t{tEff_pval}\t{tEff_eff}\t'
##    '{RNA_sig}\t{RPF_sig}\t{tEff_sig}\n'
#   
#    outfile.write(header)
#    outfile_sig.write(header)
#       
#    dna_name = ('{}_DNA_{}').format(strain, site)
#    print('dna', dna_name)
#    
#    for gene in gene_list:
#        #print(gene)
#        if gene in density_dict:
#            if dna_name in density_dict[gene]:
#                exp_depth = round(density_dict[gene][dna_name], depth_round)
#            
#                if (gene in observed_RPF_1) and (gene in observed_RPF_2) and (gene in expected_RPF_1) and (gene in expected_RPF_2):
#                    if (gene in observed_RNA_1) and (gene in observed_RNA_2) and (gene in expected_RNA_1) and (gene in expected_RNA_2):
#                        #RPF_pval, RNA_pval, tEff_pval, RPF_eff, RNA_eff, tEff_eff = 1, 1, 1, 1, 1, 1 
#                        '''replicate based BET'''
#                        #RPF    RNA Teff
#                        #242	265	138
#                        
#                        correction = 6572
#                        
#                        RNA_sig = False
#                        RPF_sig = False
#                        tEff_sig = False
#                        
#                        orpf_1 = observed_RPF_1[gene]
#                        orpf_2 = observed_RPF_2[gene]
#                        orna_1 = observed_RNA_1[gene]
#                        orna_2 = observed_RNA_2[gene]
#                        
#                        erpf_1 = exp_depth*expected_RPF_1[gene]
#                        erpf_2 = exp_depth*expected_RPF_2[gene]
#                        erna_1 = exp_depth*expected_RNA_1[gene]
#                        erna_2 = exp_depth*expected_RNA_2[gene]
#                        
##                        orpf_1 = 2558.87645
##                        orpf_2 = 2348.319711
##                        orna_1 = 3451.478548
##                        orna_2 = 3245.377347
##                        
##                        erpf_1 = 4340.053311
##                        erpf_2 = 4688.179281
##                        erna_1 = 4008.401954
##                        erna_2 = 5619.589789
#                        
#                        observed_rpf, expected_rpf, rpf_eff, rpf_pval, RPF_sig = expression_level_criteria(orpf_1, orpf_2, erpf_1, erpf_2, correction)
#                        observed_rna, expected_rna, rna_eff, rna_pval, RNA_sig = expression_level_criteria(orna_1, orna_2, erna_1, erna_2, correction)
#                        otef_1, otef_2, etef_1, etef_2, teff_eff, teff_pval, tEff_sig = expression_2_level_criteria(orpf_1, orna_1, orpf_2, orna_2, erpf_1, 
#erna_1, erpf_2, erna_2, correction)
#                                                                    
#                        outline = ('{gene}\t{DNA}\t'
#                                   '{oRPF1}\t{oRPF2}\t{oRNA1}\t{oRNA2}\t'
#                                   '{aRPF1}\t{aRPF2}\t{aRNA1}\t{aRNA2}\t'
#                                   '{eRPF1}\t{eRPF2}\t{eRNA1}\t{eRNA2}\t'
#                                   '{otEff1}\t{otEff2}\t{etEff1}\t{etEff2}\t'
#                                   '{oRPF}\t{oRNA}\t{eRPF}\t{eRNA}\t'
#                                   '{RPF_pval}\t{RPF_eff}\t'
#                                   '{RNA_pval}\t{RNA_eff}\t'
#                                   '{tEff_pval}\t{tEff_eff}\t'
#                                   '{RNA_sig}\t{RPF_sig}\t{tEff_sig}\n').format(
#                                           gene=gene, DNA=exp_depth, 
#                                           oRPF1 = orpf_1, oRPF2 = orpf_2, 
#                                           oRNA1 = orna_1, oRNA2 = orna_2, 
#                                           aRPF1 = expected_RPF_1[gene], aRPF2 = expected_RPF_2[gene], 
#                                           aRNA1 = expected_RNA_1[gene], aRNA2 = expected_RNA_2[gene],
#                                           otEff1 = otef_1, otEff2 = otef_2, etEff1 = etef_1, etEff2 = etef_2,
#                                           eRPF1 = erpf_1, eRPF2 = erpf_2, 
#                                           eRNA1 = erna_1, eRNA2 = erna_2,  
#                                           oRPF = observed_rpf, oRNA = observed_rna, 
#                                           eRPF = expected_rpf, eRNA = expected_rna, 
#                                           RPF_pval = rpf_pval, RPF_eff = rpf_eff, 
#                                           RNA_pval = rna_pval, RNA_eff = rna_eff, 
#                                           tEff_pval = teff_pval, tEff_eff = teff_eff, 
#                                           RNA_sig = RNA_sig, RPF_sig = RPF_sig, tEff_sig = tEff_sig)
#                        outfile.write(outline)
#                        
#                        if RNA_sig or RPF_sig or tEff_sig:
#                            outfile_sig.write(outline)
#                            
#                        mean_RNA_list.append(rna_eff)
#                        mean_RPF_list.append(rpf_eff)
#                        mean_tEff_list.append(teff_eff)
#                        
#                        sig_RNA = parse_sig(gene, rna_pval, rna_eff, sig_RNA)
#                        sig_RPF = parse_sig(gene, rna_pval, rpf_eff, sig_RPF) 
#                        sig_tEff = parse_sig(gene, rna_pval, teff_eff, sig_tEff)
#                
#            else:
#                print('No DNA Depth found', dna_name, gene)
#                outline = ('No DNA Depth found\t{}\t{}\n)').format(dna_name, gene)
#                outfile_call.write(outline)
#                
#    print_sig(sig_RNA, 'RNA', outfile_call)
#    print_sig(sig_RPF, 'RPF', outfile_call)
#    print_sig(sig_tEff, 'tEff', outfile_call)
#                
#    outfile.close()
#    outfile_sig.close()
#    outfile_call.close()
    
    
'''
'''
#import pickle 
#
#file = open('C:/Gresham/Project_Carolino/supplemental/teff_corrected_differences_eval_exp_dict.p','rb')
#
#
#eval_exp_dict = pickle.load(file)
#
#file.close()
#
#eval_exp_dict['n_1657_v_1743']['YLL008W']



'''
''' 
    
def output_exp_stats(eval_exp_dict):
    
    for isnorm in eval_exp_dict:
        pickle_name = ('{}_{}_eval_exp_dict.p').format(args.output_file, isnorm)
        pickle.dump(eval_exp_dict, open(pickle_name, 'wb'))
        
        outfile_name = ('{}_{}_all_calls.log').format(args.output_file, isnorm)
        outfile = open(outfile_name, 'w')
        
        print(' all output to ', outfile_name) 
        
        outfile_sig_name = ('{}_{}_sig.tsv').format(args.output_file, isnorm)
        outfile_sig = open(outfile_sig_name, 'w')
        
        print(' sig output to ', outfile_sig_name) 
        
        outfile_call_name = ('{}_{}_call.log').format(args.output_file, isnorm)
        outfile_call = open(outfile_call_name, 'w')
        
        print(' call output to ', outfile_call_name) 
        
        sig_RNA = {'low':set(), 'high':set()}
        sig_RPF = {'low':set(), 'high':set()}
        sig_tEff = {'low':set(), 'high':set()}
        
        mean_RNA_list = []
        mean_RPF_list = []
        mean_tEff_list =[]
        
        header = ('gene\tanc_dna_depth\tobs_DNA_depth\trel_DNA_depth\t'
                  'obs_RPF_1\tobs_RPF_2\tobs_RNA_1\tobs_RNA_2\t'
                  'ans_RPF_1\tans_RPF_2\tans_RNA_1\tans_RNA_2\t'
                  'exp_RPF_1\texp_RPF_2\texp_RNA_1\texp_RNA_2\t'
                  'obs_1_tEff\tobs_2_tEff\texp_1_tEff\texp_2_tEff\t'
                  'obs_mean_RPF\tobs_mean_RNA\texp_mean_RPF\texp_mean_RNA\t'
                  'RPF_pval\tRPF_eff\tRNA_pval\tRNA_eff\ttEff_pval\ttEff_eff\t'
                  'RNA_sig\tRPF_sig\ttEff_sig\tstrain\n')
        
        outfile.write(header)
        outfile_sig.write(header)
    
        for strain in eval_exp_dict[isnorm]:
            for gene in eval_exp_dict[isnorm][strain]:
                adna = eval_exp_dict[isnorm][strain][gene]['aDNA']
                exp_depth = eval_exp_dict[isnorm][strain][gene]['eDNA']
                rdna = eval_exp_dict[isnorm][strain][gene]['rDNA']
                orpf_1 = eval_exp_dict[isnorm][strain][gene]['oRPF1']
                orpf_2 = eval_exp_dict[isnorm][strain][gene]['oRPF2']
                orna_1 = eval_exp_dict[isnorm][strain][gene]['oRNA1']
                orna_2 = eval_exp_dict[isnorm][strain][gene]['oRNA2']
                arpf_1 = eval_exp_dict[isnorm][strain][gene]['aRPF1']
                arpf_2 = eval_exp_dict[isnorm][strain][gene]['aRPF2']
                arna_1 = eval_exp_dict[isnorm][strain][gene]['aRNA1']
                arna_2 = eval_exp_dict[isnorm][strain][gene]['aRNA2']
                erpf_1 = eval_exp_dict[isnorm][strain][gene]['eRPF1']
                erpf_2 = eval_exp_dict[isnorm][strain][gene]['eRPF2']
                erna_1 = eval_exp_dict[isnorm][strain][gene]['eRNA1']
                erna_2 = eval_exp_dict[isnorm][strain][gene]['eRNA2']
                otef_1 = eval_exp_dict[isnorm][strain][gene]['otEff1']
                otef_2 = eval_exp_dict[isnorm][strain][gene]['otEff2']
                etef_1 = eval_exp_dict[isnorm][strain][gene]['etEff1']
                etef_2 = eval_exp_dict[isnorm][strain][gene]['etEff2']
                observed_rpf = eval_exp_dict[isnorm][strain][gene]['oRPF']
                observed_rna = eval_exp_dict[isnorm][strain][gene]['oRNA']
                expected_rpf = eval_exp_dict[isnorm][strain][gene]['eRPF'] 
                expected_rna = eval_exp_dict[isnorm][strain][gene]['eRNA']
                rpf_pval = eval_exp_dict[isnorm][strain][gene]['RPF_pval']
                rpf_eff = eval_exp_dict[isnorm][strain][gene]['RPF_eff']
                rna_pval = eval_exp_dict[isnorm][strain][gene]['RNA_pval'] 
                rna_eff = eval_exp_dict[isnorm][strain][gene]['RNA_eff']
                teff_pval = eval_exp_dict[isnorm][strain][gene]['tEff_pval'] 
                teff_eff = eval_exp_dict[isnorm][strain][gene]['tEff_eff']
                RNA_sig = eval_exp_dict[isnorm][strain][gene]['RNA_sig']
                RPF_sig = eval_exp_dict[isnorm][strain][gene]['RPF_sig']
                tEff_sig = eval_exp_dict[isnorm][strain][gene]['tEff_sig']
                        
                outline = ('{gene}\t{aDNA}\t{eDNA}\t{rDNA}\t'
                           '{oRPF1}\t{oRPF2}\t{oRNA1}\t{oRNA2}\t'
                           '{aRPF1}\t{aRPF2}\t{aRNA1}\t{aRNA2}\t'
                           '{eRPF1}\t{eRPF2}\t{eRNA1}\t{eRNA2}\t'
                           '{otEff1}\t{otEff2}\t{etEff1}\t{etEff2}\t'
                           '{oRPF}\t{oRNA}\t{eRPF}\t{eRNA}\t'
                           '{RPF_pval}\t{RPF_eff}\t'
                           '{RNA_pval}\t{RNA_eff}\t'
                           '{tEff_pval}\t{tEff_eff}\t'
                           '{RNA_sig}\t{RPF_sig}\t{tEff_sig}\t'
                           '{strain}\n').format(
                                   gene=gene, aDNA = adna, eDNA = exp_depth, rDNA = rdna,
                                   oRPF1 = orpf_1, oRPF2 = orpf_2, oRNA1 = orna_1, oRNA2 = orna_2, 
                                   aRPF1 = arpf_1, aRPF2 = arpf_2, aRNA1 = arna_1, aRNA2 = arna_2,
                                   eRPF1 = erpf_1, eRPF2 = erpf_2, eRNA1 = erna_1, eRNA2 = erna_2,
                                   otEff1 = otef_1, otEff2 = otef_2, etEff1 = etef_1, etEff2 = etef_2,
                                   oRPF = observed_rpf, oRNA = observed_rna, 
                                   eRPF = expected_rpf, eRNA = expected_rna, 
                                   RPF_pval = rpf_pval, RPF_eff = rpf_eff, 
                                   RNA_pval = rna_pval, RNA_eff = rna_eff, 
                                   tEff_pval = teff_pval, tEff_eff = teff_eff, 
                                   RNA_sig = RNA_sig, RPF_sig = RPF_sig, tEff_sig = tEff_sig,
                                   strain = strain)
                outfile.write(outline)
            
                if RNA_sig or RPF_sig or tEff_sig:
                    outfile_sig.write(outline)
                    print(outline)
                    
                mean_RNA_list.append(rna_eff)
                mean_RPF_list.append(rpf_eff)
                mean_tEff_list.append(teff_eff)
                
                sig_RNA = parse_sig(gene, rna_pval, rna_eff, sig_RNA)
                sig_RPF = parse_sig(gene, rna_pval, rpf_eff, sig_RPF) 
                sig_tEff = parse_sig(gene, rna_pval, teff_eff, sig_tEff)
                                            
                print_sig(sig_RNA, 'RNA', outfile_call)
                print_sig(sig_RPF, 'RPF', outfile_call)
                print_sig(sig_tEff, 'tEff', outfile_call)
                        
    outfile.close()
    outfile_sig.close()
    outfile_call.close()
    
def stats_on_counts(gene, strain, isnorm, anc_dna, exp_depth, rel_dna,
                    orpf_1, orpf_2, orna_1, orna_2,
                    erpf_1, erpf_2, erna_1, erna_2,
                    arpf_1, arpf_2, arna_1, arna_2,
                    eval_exp_dict):
           
    correction = 6572
                        
    RNA_sig = False
    RPF_sig = False
    tEff_sig = False
    
    observed_rpf, expected_rpf, rpf_eff, rpf_pval, RPF_sig = expression_level_criteria(orpf_1, orpf_2, erpf_1, erpf_2, correction)
    observed_rna, expected_rna, rna_eff, rna_pval, RNA_sig = expression_level_criteria(orna_1, orna_2, erna_1, erna_2, correction)
    otef_1, otef_2, etef_1, etef_2, teff_eff, teff_pval, tEff_sig = expression_2_level_criteria(orpf_1, orna_1, orpf_2, orna_2, 
                                                                                                arpf_1, arna_1, arpf_1, arna_2, correction)
    if isnorm not in eval_exp_dict:
        eval_exp_dict[isnorm] = {}
    
    if strain not in eval_exp_dict[isnorm]:
        eval_exp_dict[isnorm][strain]={}
    
    if gene not in eval_exp_dict[isnorm][strain]:
        eval_exp_dict[isnorm][strain][gene] = {'gene': gene, 'aDNA': anc_dna, 'eDNA': exp_depth, 'rDNA': rel_dna, 'strain': strain,
                 'oRPF1': orpf_1, 'oRPF2': orpf_2, 'oRNA1': orna_1, 'oRNA2': orna_2,
                 'aRPF1': arpf_1, 'aRPF2': arpf_2, 'aRNA1': arna_1, 'aRNA2': arna_2,
                 'eRPF1': erpf_1, 'eRPF2': erpf_2, 'eRNA1': erna_1, 'eRNA2': erna_2,
                 'otEff1': otef_1, 'otEff2': otef_2, 'etEff1': etef_1, 'etEff2': etef_2,
                 'oRPF': observed_rpf, 'oRNA': observed_rna,
                 'eRPF': expected_rpf, 'eRNA': expected_rna,
                 'RPF_pval': rpf_pval, 'RPF_eff': rpf_eff,
                 'RNA_pval': rna_pval, 'RNA_eff': rna_eff,
                 'tEff_pval': teff_pval, 'tEff_eff': teff_eff,
                 'RNA_sig': RNA_sig, 'RPF_sig': RPF_sig, 'tEff_sig': tEff_sig}
            
    return(eval_exp_dict)
            
def unpackbits(x,num_bits=12):
    '''
    SAM flags are bit encoded - this function seperates them and assigns labels
    '''
    
    xshape = list(x.shape)
    x = x.reshape([-1,1])
    to_and = 2**np.arange(num_bits).reshape([1,num_bits])
    upb = (x & to_and).astype(bool).astype(int).reshape(xshape + [num_bits])

    #0  (rp)    read_paired
    #1  (rmp)    read_mapped_in_proper_pair
    #2  (ru)    read_unmapped
    #3  (mu)    mate_unmapped
    #4  (rrs)    read_reverse_strand
    #5  (mrs)    mate_reverse_strand
    #6  (fip)    first_in_pair
    #7  (sip)    second_in_pair
    #8  (npa)    not_primary_alignment
    #9  (rfp)    read_fails_platform
    #10 (pcr)    read_is_PCR_or_optical_duplicate
    #11 (sa)    supplementary_alignment
    """
    strand = unpackbits(np.array([int(line.split('\t')[1])]))[0][4]
    such that 0 == '+' and 1 == '-'
    """
    
    """ DISCORDANT definition (from samblaster)
        Both side of the read pair are mapped (neither FLAG 0x4 or 0x8 is set).
        The properly paired FLAG (0x2) is not set.
        Note: We implemented an additional criteria to distinguish between strand re-orientations and distance issues
        Strand Discordant reads must be both on the same strand.
    """
        
    """ SPLIT READS
        Identify reads that have between two and --maxSplitCount [2] primary and supplemental alignments.
        Sort these alignments by their strand-normalized position along the read.
        Two alignments are output as splitters if they are adjacent on the read, and meet these criteria:
            each covers at least --minNonOverlap [20] base pairs of the read that the other does not.
            the two alignments map to different reference sequences and/or strands. 
            the two alignments map to the same sequence and strand, and represent a SV that is at least --minIndelSize [50] in length, 
            and have at most --maxUnmappedBases [50] of un-aligned base pairs between them.
        Split read alignments that are part of a duplicate read will be output unless the -e option is used.
    """
    
    return(upb) 
    
def parse_cigar(cigar, sequence):
    """This function calculates the offset for the read based on the match
        returns an sequence uncorrected to sign
    """

    if cigar.count('M') == 1:
        #print(cigar, sequence)
        left_cut = 0
        right_cut = 0
        
        left_list = re.split('M|S|D|I|H|N', cigar.split('M')[0])[0:-1]
        M = re.split('M|S|D|I|H|N', cigar.split('M')[0])[-1]
        right_list = re.split('M|S|D|I|H|N', cigar.split('M')[1])
        
        for each in left_list:
            if each: 
                left_cut += int(each)
                
        for each in right_list:
            if each: 
                right_cut -= int(each)
        
        n_cigar = ('{}M').format(M)

        if right_cut:
            n_sequence = sequence[left_cut:right_cut]
        else:
            n_sequence = sequence[left_cut:]
                        
        #print (left_cut, right_cut,  n_cigar, n_sequence)
        return(True, n_cigar, n_sequence)
            
    else:
        return(False, '', '')
    
#def find_sig_in_dict(xname, yname):
#    global density_dict
        
def build_pickle_map(map_file_name):
    '''
    # This function builds the "paths" object. This object contains the metadata such as strain name, replicates and ancestor
        _x_ rename 'paths' to 'map' for clarity
    '''
    
    map_object = {}
    #paths_file_name = 'C:\Gresham\Project_Carolino\int_pickles\intermediate_path_file.tab.txt'
    map_file = open(map_file_name)
    
    experimental_object_df = pd.read_csv(map_file_name)
    experimental_object_df.to_dict()
    
    
    #sample_type	sample_name	replicate	anc_strain	obs_path	dna_path
    #RNA	DGY1657	R1	DGY1657	/scratch/ps163/Carolina_01_17_2021/bam/expression/RNA_DGY1657_R1.sorted.sam	/scratch/ps163/Carolina_01_17_2021/depth/DGY1657_abs_depth.p	/scratch/ps163/Carolina_01_17_2021/bam/pickles/	/scratch/ps163/Carolina_01_17_2021/bam/pickles/		
    for line in map_file:
        if line[0]!= '#':
            line = line.strip()
            sample_type, sample_name, replicate, anc_strain, obs_path, reverse_strand, dna_path = line.split('\t')[0:7]        
            
            uid = ('{}_{}_{}').format(sample_type, sample_name, replicate)
       
            output_path = ('{}').format(args.output_file)
            
            if sample_type not in map_object:
                map_object[sample_type] = {}
                
            if sample_name not in map_object[sample_type]:
                map_object[sample_type][sample_name]={}
            
            if replicate not in map_object[sample_type][sample_name]:
                map_object[sample_type][sample_name][replicate] = {'notes':[], 'aligned_read_ct':0}
            
            map_object[sample_type][sample_name][replicate]['uid'] = uid
            map_object[sample_type][sample_name][replicate]['anc_strain'] = anc_strain
            map_object[sample_type][sample_name][replicate]['obs_path'] = obs_path
            map_object[sample_type][sample_name][replicate]['dna_path'] = dna_path
            map_object[sample_type][sample_name][replicate]['output_path'] = output_path
            map_object[sample_type][sample_name][replicate]['reverse_strand'] = reverse_strand         
            
    return(map_object)
    
        
def build_regions_to_filter(infile_name):
    regions_to_filter = {}
    
    infile = open(infile_name)
    for line in infile:
        if line[0] != '#':
            chromo = line.split('\t')[0]
            start = int(line.split('\t')[1])
            stop = int(line.split('\t')[2])
            sign = line.split('\t')[5].strip()
            
            if chromo not in regions_to_filter:
                regions_to_filter[chromo] = {'+':set(), '-':set()}
            
            for nt in range(start, stop+1):
                if sign == '.':
                    regions_to_filter[chromo]['+'].add(nt)
                    regions_to_filter[chromo]['-'].add(nt)
                else:
                    regions_to_filter[chromo][sign].add(nt)

    infile.close()
    
    return(regions_to_filter)
        
def filtered_region(chromo, start, stop, sign, regions_to_filter):
        
    if chromo in regions_to_filter:
        if sign in regions_to_filter[chromo]:
            
            filtered_nts = regions_to_filter[chromo][sign]
            for nt in range(start,stop+1):
                if nt in filtered_nts:
                    return(False)
                    
    return(True)
                
def parse_sam_file(samfile_name, regions_to_filter, outpath, reverse=False, minsize = 20, maxsize = 36):
    '''
    open sam file and populate read dictionary, save as pickle
    '''
    #@PG	
    #@CO
    #SRR10302098.18096714	0	I	24007	1	1M	*	0	0	A	*	NH:i:3	HI:i:1	AS:i:29	nM:i:0
    #SRR10302098.11813844	16	I	24022	1	1M	*	0	0	G	*	NH:i:3	HI:i:1	AS:i:29	nM:i:0
    #SRR10302098.19932359	16	I	24022	1	1M	*	0	0	G	*	NH:i:3	HI:i:1	AS:i:29	nM:i:0
    
    global chromo_set

    read_to_locus = {}
    chromo_to_read = {}
    locus_depth = {}
    
    locus_uid_depth = {}
    
    strand_to_sign = {0:'+', 1:'-'}
    if reverse:
        strand_to_sign = {0:'-', 1:'+'}
    
    uid_ct = {}
    #uid_lookup = {}

    #samfile = open(args.samfile_name)
    samfile = open(samfile_name)
    print('Processing sam file ...', samfile_name)
    
    #adjusted_sam_file_name = samfile_name.split('.sam')[0] + '_psite_adj.sam'
    #adjusted_sam_file = open(adjusted_sam_file_name, 'w')

    for line in samfile:
#        if line[0] == '@':
#            adjusted_sam_file.write(line)
                    
        if line[0] != '@':
            raw_uid = line.split('\t')[0]
            chromo = line.split('\t')[2]
            
            if chromo in chromo_set:
                cigar = line.split('\t')[5]
                sequence = line.split('\t')[9]

                ### circumventing parse_cigar for short read rna and rpf 
                process, n_cigar, n_sequence = parse_cigar(cigar, sequence)
                
                if process:
                    sign = strand_to_sign[unpackbits(np.array([int(line.split('\t')[1])]))[0][4]]

                    start = int(line.split('\t')[3])
                    size = len(n_sequence)
                    stop = start + size
                    
                    #filter by size
                    if size >= minsize and size <= maxsize:
                                
                        #filtered_region will toss read if any overlap with a region
                        if filtered_region(chromo, start, stop, sign, regions_to_filter):
                            
                            # handles splits and multimappers
                            # will also handle total aligned read count
                            if raw_uid not in uid_ct:
                                uid_ct[raw_uid] = 0
                                
                            else:
                                uid_ct[raw_uid] +=1
                                
                            uid = ('{}.{}').format(raw_uid, (uid_ct[raw_uid]))
                            
                            # with uid look up location   
                            if chromo not in read_to_locus:
                                read_to_locus[chromo] = {}
                            
                            if uid not in read_to_locus[chromo]:
                                read_to_locus[chromo][uid] = [chromo, start, stop, sign]
                            else:
                                print('uid duplication conflict', uid)
                            
                            # with chromo look up all associated uids
                            if chromo not in chromo_to_read:
                                chromo_to_read[chromo] = set()
                            
                            chromo_to_read[chromo].add(uid)
                            
                            if chromo not in locus_uid_depth:
                                locus_uid_depth[chromo] = {'+':{}, '-':{}}
            
                            # with location look up depth.
                            if chromo not in locus_depth:
                                locus_depth[chromo] = {'+':{}, '-':{}}
                            
                            for nt in range(start, stop+1):
                                if nt not in locus_depth[chromo][sign]:
                                    locus_depth[chromo][sign][nt] = 0
                                                                
                                locus_depth[chromo][sign][nt] += 1
                                
                            # with location look up uid.
                                if nt not in locus_uid_depth[chromo][sign]:
                                    locus_uid_depth[chromo][sign][nt] = set()
                                    
                                locus_uid_depth[chromo][sign][nt].add(raw_uid)
                        
    samfile.close()
    
    for chromo in chromo_set:
        print(locus_uid_depth.keys())
        chromo_locus_uid_depth = locus_uid_depth[chromo]
        pickle_name = ('{}_{}_unnormalized_locus_uid_depth.p').format(outpath, chromo)
        pickle.dump(chromo_locus_uid_depth, open(pickle_name, 'wb'))
    
        chromo_locus_depth = locus_depth[chromo]
        pickle_name = ('{}_{}_unnormalized_locus_depth.p').format(outpath, chromo)
        pickle.dump(chromo_locus_depth, open(pickle_name, 'wb'))
        
        chromo_chromo_to_read = chromo_to_read[chromo]
        pickle_name = ('{}_{}_chromo_to_read.p').format(outpath, chromo)
        pickle.dump(chromo_chromo_to_read, open(pickle_name, 'wb'))
        
        pickle_name = ('{}_{}_read_to_locus.p').format(outpath, chromo)
        pickle.dump(read_to_locus, open(pickle_name, 'wb'))

    return(len(uid_ct))
    
def normalize_reads(sinput, output, downsample_frequency):
    for chromo in chromo_set:
        read_to_locus_name = ('{}_{}_read_to_locus.p').format(sinput, chromo)
        ct = 0
        locus_depth = {}
        locus_uid_depth = {}
        
        read_to_locus_file = open(read_to_locus_name,'rb')
        read_to_locus = pickle.load(read_to_locus_file)
        read_to_locus_file.close()
           
        for uid in read_to_locus[chromo]:
            if random.random() <= downsample_frequency:
                ct+=1
                chromo, start, stop, sign = read_to_locus[chromo][uid]
    
                # with location look up depth.
                if chromo not in locus_depth:
                    locus_depth[chromo] = {'+':{}, '-':{}}
                
                if chromo not in locus_uid_depth:
                    locus_uid_depth[chromo] = {'+':{}, '-':{}}
                
                for nt in range(start, stop+1):
                    if nt not in locus_depth[chromo][sign]:
                        locus_depth[chromo][sign][nt] = 0
                    
                    locus_depth[chromo][sign][nt] += 1  
                    
                # with location look up uid.
                    if nt not in locus_uid_depth[chromo][sign]:
                        locus_uid_depth[chromo][sign][nt] = set()
                        
                    locus_uid_depth[chromo][sign][nt].add(uid)
        
        outline = ('Chromo: {} Original read count: {}\t Downsampled to :{}\t {}%\n').format(
                chromo, len(read_to_locus[chromo]), ct, ct/len(read_to_locus[chromo]))
        print(outline)    
        
        normalized_locus_name = ('{}_{}_normalized_locus_depth.p').format(output, chromo)
        pickle.dump(locus_depth, open(normalized_locus_name, 'wb'))
        
        normalized_locus_uid_name = ('{}_{}_normalized_locus_uid_depth.p').format(output, chromo)
        pickle.dump(locus_uid_depth, open(normalized_locus_uid_name, 'wb'))
        
    return(normalized_locus_name, normalized_locus_uid_name)
    
def parse_density_file(readtype, strain, replicate, site, suffix):
    global density_dict
    global relative_depth_dict
    global coord_dict

    file_name = ('{}{}_{}_{}_{}.{}').format(args.input_abundance_file, readtype, strain, replicate, site, suffix)
    print('opening ', file_name)
    infile = open(file_name)
    
    temp_log_filename = file_name = ('{}{}_{}_{}_{}_{}.log').format(args.output_file, readtype, strain, replicate, site, suffix)
    temp_log_file =open(temp_log_filename, 'w')
        
    col_name = ('{}_{}_{}_{}').format(strain, readtype, replicate, site)
    dna_name = ('{}_DNA_{}').format(strain, site)

    for line in infile:
        if line[0] == '#':
            pass 
            #print(line)
        if line[0] != '#':
            line = line.strip()
            chromo =line.split('\t')[0]
            start = int(line.split('\t')[1])
            stop = int(line.split('\t')[2])
            gene = line.split('\t')[3]
            sign = line.split('\t')[5]
            
            read_abun = float(line.split('\t')[9])
            
#            if strain not in density_dict:
#                density_dict[strain] = {}
            
            if gene not in density_dict:
                density_dict[gene] = {}
                
            if gene not in coord_dict:
                coord_dict[gene] = {}

            density_dict[gene][col_name] = read_abun
            
            coord_dict[gene][col_name] = {'chromo':chromo, 'start': start, 'stop': stop, 'sign': sign}
            
            if dna_name not in density_dict[gene]:
                if dna_depth:
                    #gene_deets = coord_dict[gene]
                    temp_list = []
                    for depth_nt in range(start, stop+1):
                        temp_list.append(relative_depth_dict[strain][chromo][depth_nt])
                        
                    median_region_depth = np.median(temp_list)
                
                else:
                    median_region_depth = 1
                
                density_dict[gene][dna_name] = median_region_depth
                
                outline = ('{chromo}\t{start}\t{stop}\t{gene}\t{score}\t{sign}\n').format(
                        chromo=chromo, start=start, stop=stop, gene=gene, score=median_region_depth, sign=sign)
                temp_log_file.write(outline)
    
    infile.close()
    temp_log_file.close()
    
def add_teff(strain, replicate, site):
    global density_dict

    rpf_col = ('{}_RPF_{}_{}').format(strain, replicate, site)
    rna_col = ('{}_RNA_{}_{}').format(strain, replicate, site)
    teff_col = ('{}_tEff_{}_{}').format(strain, replicate, site)
    
    for gene in density_dict:
        if (rpf_col in density_dict[gene]) and (rna_col in density_dict[gene]):
            density_dict[gene][teff_col]=(density_dict[gene][rpf_col]/max(density_dict[gene][rna_col],1))
        else:
            density_dict[gene][teff_col]=0        

def load_pickle(pickle_file_name):
    file = open(pickle_file_name,'rb')
    temp_pickle = pickle.load(file)
    file.close()
    
    return(temp_pickle)
    
if args.calculate_depth:
    # TODO tie this into the experiment object    
    if args.filter_regions:
        regions_to_filter = build_regions_to_filter(args.filter_regions)
    else:
        regions_to_filter = {}
        
    infile_name = ('/scratch/ps163/Carolina_03_18_2021/depth/DNA_DGY1657_depth.tab')
    outfile_name = ('/scratch/ps163/Carolina_03_18_2021/depth/DGY1657_abs_depth.p')
    get_genome_depth(infile_name, outfile_name, regions_to_filter, False, '')
    
    relative_depth_analysis = True
    relative_depth_file = ('/scratch/ps163/Carolina_03_18_2021/depth/DGY1657_abs_depth.p')
    
    for sample_name in ['DGY1726', 'DGY1728', 'DGY1735', 'DGY1741', 'DGY1743']: 
        infile_name = ('/scratch/ps163/Carolina_03_18_2021/depth/DNA_{}_depth.tab').format(sample_name)
        outfile_name = ('/scratch/ps163/Carolina_03_18_2021/depth/{}_abs_depth.p').format(sample_name)
        
        get_genome_depth(infile_name, outfile_name, regions_to_filter, relative_depth_analysis, relative_depth_file)
    
def populate_uid_into_steps(start, step, step_size, uid_depth_dict, positional_dna_depth_dict, depth_mode = 'observed'):
    wstart = start+step*step_size
    wstop = start+((step+1)*step_size)
    
    temp_set = set()
    
    for nt in range(wstart, wstop+1): 
        if nt in uid_depth_dict:
            for uid in uid_depth_dict[nt]:
                temp_set.add(uid)
                
    return_value = len(temp_set)
    
    if depth_mode == 'expected':
        temp_depth_list = []
        
        for nt in range(wstart, wstop+1):
            if nt in positional_dna_depth_dict:
                temp_depth_list.append(positional_dna_depth_dict[nt])
            else:
                temp_depth_list.append(0)
                
        return_value *= max(round(np.median(temp_depth_list)),1)

    return(return_value)
    
def setup_level_one(evo_0, evo_1, anc_0, anc_1, correction, process_list, read_list, pval_list, nt_list, adjusted_nt):
    _obs_mean, _exp_mean, eff, pval, process = expression_level_criteria(evo_0, evo_1, anc_0, anc_1, correction)

    process_list.append(process)

    read_list.append(eff)
    pval = max(0.0001, pval)
    pval_list.append(-1*np.log10(pval))
    nt_list.append(adjusted_nt)
        
    return(process_list, read_list, pval_list, nt_list)
    
def calculate_expected_rpf(evo_rna_0, evo_rna_1, anc_rpf_0, anc_rna_0, anc_rpf_1, anc_rna_1):
    
    anc_teff_0 = (anc_rpf_0/max(anc_rna_0,1))
    anc_teff_1 = (anc_rpf_1/max(anc_rna_1,1))
    
    anc_teff = ((anc_rpf_0+anc_rpf_1)/max((anc_rna_0+anc_rna_1),1))
    
    exp_0 = round(evo_rna_0 * anc_teff)
    exp_1 = round(evo_rna_1 * anc_teff)
    return(exp_0, exp_1)
        
def setup_level_two(evo_rpf_0, evo_rna_0, evo_rpf_1, evo_rna_1,
                    anc_rpf_0, anc_rna_0, anc_rpf_1, anc_rna_1, correction,
                    process_list, teff_list, teff_pval_list, teff_nt_list, adjusted_nt):
    
    _otef_1, _otef_2, _etef_1, _etef_2, teff_eff, teff_pval, process = expression_2_level_criteria(
            evo_rpf_0, evo_rna_0, evo_rpf_1, evo_rna_1,
            anc_rpf_0, anc_rna_0, anc_rpf_1, anc_rna_1, correction)
    
    process_list.append(process)
    
    teff_list.append(teff_eff)
    teff_pval = max(0.0001, teff_pval)
    teff_pval_list.append(-1*np.log10(teff_pval))
    
    teff_nt_list.append(adjusted_nt)
        
    return(process_list, teff_list, teff_pval_list, teff_nt_list)
    
def make_relative_depth_dict(evo_dna_depth, anc_dna_depth):
    relative_depth_dict = {}
    
    max_nt = max(
            max(list(anc_dna_depth.keys())),
            max(list(evo_dna_depth.keys()))
            )

    for nt in range(max_nt+1):
        if (nt in evo_dna_depth):
            edd_nt = evo_dna_depth[nt]
        else:
            edd_nt = 0
        
        if (nt in anc_dna_depth):
            add_nt = anc_dna_depth[nt]
            
            if add_nt == 0:
                add_nt = 1
        else:
            add_nt = 1
                
        relative_depth_dict[nt] = edd_nt/add_nt
    
    return(relative_depth_dict)

def pr_plotter(nt_list, read_list, pval_list, ismax, outfile, name, readtype, regions):
    
    plt.scatter(nt_list, read_list, alpha=0.2,  c=pval_list, cmap='coolwarm')
    
    for each in regions:
        xlist = []
        ylist = []
        start = regions[each]['start']
        stop = regions[each]['stop']
        for nt in range(start, stop + 1):
            xlist.append(nt)
            ylist.append(0.1)
        
        plt.plot(xlist, ylist)
    
    plt.ylim(0, ismax)
    
    plt.colorbar()
    
    name = str(name)
    
    outfile_name = ('{outfile}_1657_v_{name}_{readtype}_plot.pdf').format(outfile = outfile, 
                   name = name, readtype = readtype)
    plt.savefig(outfile_name)
    plt.close()
    
def collapse_regions(uncollapsed_dict):
    for region_q in uncollapsed_dict:
        for region_s in uncollapsed_dict:
            if region_q != region_s:
                combine = False
        
                qstart, qstop = uncollapsed_dict[region_q]
                sstart, sstop = uncollapsed_dict[region_s]
                
                if (qstart <= sstart) and (qstop >= sstart):
                    combine = True
                        
                if (qstart <= sstop) and (qstop >= sstop):
                    combine = True
                    
                if combine:
                    nregion = max(uncollapsed_dict)+1
                    nstart = min(qstart, sstart)
                    nstop = max(qstop, sstop)
                    
                    del uncollapsed_dict[region_q]
                    del uncollapsed_dict[region_s]
                    
                    uncollapsed_dict[nregion] = [nstart, nstop]
                    
                    return(uncollapsed_dict, True)
    
    return(uncollapsed_dict, False)

def pr_density_build(name, process_list, ratio_list, nt_list, pval_list, 
                     pr_dict, window_size, chromo, readtype):
    
    if (len(ratio_list) != len(pval_list)) and (len(nt_list) != len(pval_list)) and (len(nt_list) != len(process_list)):
        print('length mismatch error')
        1/0
    
    nt_to_index = {}
    index_to_nt = {}
    
    nt_set = set()
    
    ct = 0
    pr_process = False
    
    nt_dict = {}
        
    print(process_list)
    
    for index in range(len(nt_list)):
        if process_list[index]:
            nt = nt_list[index]
            nt_to_index[nt] = index
            index_to_nt[index] = nt
        
            if pval_list[index] >= 1.301:
                nt_set.add(index)
            
    for index in range(len(nt_list)):
        if process_list[index]:
            nt = nt_list[index]
        
            for next_index in range(window_size):
                if index + next_index in nt_set:
                    ct+=1
        
            if ct >= window_size * 0.9:
                if nt not in nt_dict:
                    nt_dict[nt] = []
                    
                nt_dict[nt].append(ratio_list[index])

    nt_sig_list = list(nt_dict.keys())
    
    if len(nt_sig_list) > 0:
        #make regions
        uncollapsed_regions = {}
        regions = {}
        added_set= set()
        
        
        
        start = 0
        
        for nt in nt_sig_list:
            print(nt)
            if nt not in added_set:
                start = nt
                stop = nt
                    
                nt_increment = 1
                breaks = 0
                
                while breaks <= 30:               
                    if (nt + nt_increment) in nt_sig_list:
                        stop = (nt + nt_increment)
                        breaks = 0
                    else:
                        breaks += 1
                        
                    nt_increment += 1
                
                if (breaks >= 30) and (start != stop):
                    for each_nt in range(start, stop+1):
                        added_set.add(each_nt)
                    
                    uncollapsed_regions[len(uncollapsed_regions)] = [start, stop]
        
        print(uncollapsed_regions)
        
        combine = True
        while combine:
            uncollapsed_regions, combine = collapse_regions(uncollapsed_regions)
        
        regions = uncollapsed_regions
        
        print(regions)
                
        for region in regions:
            start, stop = regions[region]
    
            ratios = []
            for nt in range(start, stop + 1):
                if nt in nt_to_index:
                    ratios.append(ratio_list[nt_to_index[nt]])
                else:
                    ratios.append(np.nan)
            
            if chromo not in pr_dict:
                pr_dict[chromo] = {}
                
            if readtype not in pr_dict[chromo]:
                pr_dict[chromo][readtype] = {}              
                
            if name not in pr_dict[chromo][readtype]:
                pr_dict[chromo][readtype][name] = {}
                
            pr_dict[chromo][readtype][name][region] = {'start': start, 'stop': stop, 'ratios':ratios}
            pr_process = True
            
        print('pr_dict:', chromo, readtype, name, region, pr_dict)
                                          
    return(pr_dict, pr_process)            
        
def pr_plot(name, chromo, original_start, stop, sign,
            anc_rpf_1_uid_depth, anc_rpf_2_uid_depth,
            anc_rna_1_uid_depth, anc_rna_2_uid_depth,
            evo_rpf_1_uid_depth, evo_rpf_2_uid_depth,
            evo_rna_1_uid_depth, evo_rna_2_uid_depth,
            positional_dna_depth_dict, pr_dict):
    
    outfile = 'temp'

    rna_nt_list = [original_start-1]
    rpf_nt_list = [original_start-1]
    teff_nt_list = [original_start-1]
    
    teff_list = [0]
    rpf_list = [0]
    rna_list = [0]
    
    teff_pval_list = [0]
    rpf_pval_list = [0]
    rna_pval_list = [0]
    
    rna_process_list = [False]
    rpf_process_list = [False]
    teff_process_list = [False]
    
    correction = 0
    step_increment = 0
    #for step_mulitplier in range(1,2):
    for step_mulitplier in range(1,16):
        step_size = 7*step_mulitplier
        steps = (stop - original_start) // step_size
        step_increment += 1
        
        correction += steps

    print(correction)
    step_increment = 0
    #for step_mulitplier in range(1,2):
    for step_mulitplier in range(1,16):
        step_size = 7*step_mulitplier
        steps = (stop - original_start) // step_size
        step_increment += 1
                       
        for step in range(steps+1):            
            anc_rpf_0 = populate_uid_into_steps(original_start, step, step_size, anc_rpf_1_uid_depth[chromo][sign], positional_dna_depth_dict)
            anc_rpf_1 = populate_uid_into_steps(original_start, step, step_size, anc_rpf_2_uid_depth[chromo][sign], positional_dna_depth_dict)
            anc_rna_0 = populate_uid_into_steps(original_start, step, step_size, anc_rna_1_uid_depth[chromo][sign], positional_dna_depth_dict)
            anc_rna_1 = populate_uid_into_steps(original_start, step, step_size, anc_rna_2_uid_depth[chromo][sign], positional_dna_depth_dict)
            #
            evo_rpf_0 = populate_uid_into_steps(original_start, step, step_size, evo_rpf_1_uid_depth[chromo][sign], positional_dna_depth_dict)
            evo_rpf_1 = populate_uid_into_steps(original_start, step, step_size, evo_rpf_2_uid_depth[chromo][sign], positional_dna_depth_dict)
            evo_rna_0 = populate_uid_into_steps(original_start, step, step_size, evo_rna_1_uid_depth[chromo][sign], positional_dna_depth_dict)
            evo_rna_1 = populate_uid_into_steps(original_start, step, step_size, evo_rna_2_uid_depth[chromo][sign], positional_dna_depth_dict)
            #
            exp_rna_0 = populate_uid_into_steps(original_start, step, step_size, anc_rna_1_uid_depth[chromo][sign], positional_dna_depth_dict, depth_mode = 'expected')
            exp_rna_1 = populate_uid_into_steps(original_start, step, step_size, anc_rna_2_uid_depth[chromo][sign], positional_dna_depth_dict, depth_mode = 'expected')
            exp_rpf_0, exp_rpf_1 = calculate_expected_rpf(evo_rna_0, evo_rna_1, anc_rpf_0, anc_rna_0, anc_rpf_1, anc_rna_1)
            #
            first_nt = (step*step_size)
            last_nt = (step+1)*step_size-1
            midpoint = (first_nt + last_nt) // 2
            adjusted_nt = (original_start)+(midpoint)
            
            #depth corrected
            rna_process_list, rna_list, rna_pval_list, rna_nt_list = setup_level_one(evo_rna_0, evo_rna_1, exp_rna_0, exp_rna_1, correction, rna_process_list, rna_list, rna_pval_list, rna_nt_list, adjusted_nt)
            rpf_process_list, rpf_list, rpf_pval_list, rpf_nt_list = setup_level_one(evo_rpf_0, evo_rpf_1, exp_rpf_0, exp_rpf_1, correction, rpf_process_list, rpf_list, rpf_pval_list, rpf_nt_list, adjusted_nt)
            teff_process_list, teff_list, teff_pval_list, teff_nt_list = setup_level_two(evo_rpf_0, evo_rna_0, evo_rpf_1, evo_rna_1,
                    exp_rpf_0, exp_rna_0, exp_rpf_1, exp_rna_1, correction,
                    teff_process_list, teff_list, teff_pval_list, teff_nt_list, adjusted_nt)
                                                            
#    ismax = max(max(teff_list), 
#                max(rpf_list), 
#                max(rna_list))
#            
    if len(rna_list) > 20 and max(rna_process_list):
        pr_dict, pr_process = pr_density_build(name, rna_process_list, rna_list, rna_nt_list, rna_pval_list, 
                                      pr_dict, 30, chromo, 'rna')
        if pr_process:
            ismax = max(rna_list)
            pr_plotter(rna_nt_list, rna_list, rna_pval_list, ismax, outfile, name, 'rna', pr_dict[chromo]['rna'][name])

    if len(rpf_list) > 20 and max(rpf_process_list):
        print('rpf_nt_list', len(rpf_nt_list), len(set(rpf_nt_list)))
        pr_dict, pr_process = pr_density_build(name, rpf_process_list, rpf_list, rpf_nt_list, rpf_pval_list, 
                                      pr_dict, 30, chromo, 'rpf')
        if pr_process:
            ismax = max(rpf_list)
            pr_plotter(rpf_nt_list, rpf_list, rpf_pval_list, ismax, outfile, name, 'rpf', pr_dict[chromo]['rpf'][name])
    
    if len(teff_list) > 20 and max(teff_process_list):
        pr_dict, pr_process = pr_density_build(name, teff_process_list, teff_list, teff_nt_list, teff_pval_list, 
                                      pr_dict, 30, chromo, 'teff')
        if pr_process:
            ismax = max(teff_list)
            pr_plotter(teff_nt_list, teff_list, teff_pval_list, ismax, outfile, name, 'teff', pr_dict[chromo]['teff'][name])
    
    return(pr_dict)
    
                        
def eval_regions(nt_map, heat_map):
    nt_list = list(nt_map.keys())
    regions_dict = {}
    
    if nt_list:
        nt_list.sort()
        x = []
        y = []
        z = []
        
        for nt in nt_list:
            x.append(nt)
            y.append(nt_map[nt])
            z.append(heat_map[nt])
            
        plt.scatter(x, y, alpha=0.5,  c=z, cmap='Greens')
        
        outfile_name = ('{}_1657_v_1743_heat.pdf').format(name)
        plt.savefig(outfile_name)   
        plt.close()
        
    if nt_list:
        added_set = set()
    
        for nt in range(min(nt_list), max(nt_list)+1):            
            if nt not in added_set:
                added_set.add(nt)
                nt_start = nt
                print('start', nt)
                
                nt_stop = nt
                
                patience = 28
                while patience > 0:
                    patience -= 1
                    
                    if (nt_stop + 1) in nt_list:
                        added_set.add(nt_stop + 1)
                        
                        print(nt_stop, patience)
                        patience = min(patience + 1, 28)
                    
                    nt_stop += 1
                    
                regions_dict[len(regions_dict)]=[nt_start, nt_stop]
                
    print(len(regions_dict))
        
    return(regions_dict)
            



    

        
def build_gene_by_dna_depth(locus_to_name, chromo_to_locus, experimental_name = 'dna_depth_by_gene', output_file=args.output_file):
    
    experiment_object_name = args.experiment_object
    experiment_object = load_pickle(experiment_object_name)
    
    sample_to_dna_dict = {}
    
    dna_depth_dict = {}
    
    for readtype in ['RNA', 'RPF']:
        for sample_name in experiment_object[readtype]:               
            if sample_name not in sample_to_dna_dict:
                sample_to_dna_dict[sample_name] = experiment_object[readtype][sample_name]['R1']['dna_path']

    for sample_name in sample_to_dna_dict:
        dna_source_path = sample_to_dna_dict[sample_name]
        dna_sample = load_pickle(dna_source_path)
        outline = ('Loading DNA depth file: {}\n{}').format(sample_name, dna_source_path)
        print(outline)
        
        for chromo in chromo_set:
            if chromo in dna_sample:
                print('starting chromosome: ', chromo)
                
                locus_list = chromo_to_locus[chromo]
                                
                for locus in locus_list:
                    dna_depths = []
                    ch, start, stop, sign = locus
                    key = ('{}:{}-{},{}').format(ch, start, stop, sign)
                    
                    nameset = locus_to_name[key]
                                       
                    for nt in range(start, stop+1):
                        if nt in dna_sample[chromo]:
                            #for nt in dna_sample[chromo]:
                                dna_depths.append(dna_sample[chromo][nt])
                                
                    if sum(dna_depths) > 0:
                        for name in nameset:
                            if name not in dna_depth_dict:
                                dna_depth_dict[name] = {}
                                                    
                            dna_depth_dict[name][sample_name] = round(np.median(dna_depths),5)
                                                
    dna_df = pd.DataFrame.from_dict(dna_depth_dict, orient='index')
    df_name = ('{}/gene_median_depth_DNA.csv').format(output_file)
    dna_df.to_csv(df_name)
                
    dna_depth_by_gene_name = ('{}/dna_depth_by_gene_dict.p').format(output_file)
    pickle.dump(dna_depth_dict, open(dna_depth_by_gene_name, 'wb'))
    
    experiment_object[experimental_name]=dna_depth_by_gene_name
    pickle.dump(experiment_object, open(experiment_object_name, 'wb'))
    
    return(dna_depth_dict)
    
def process_positional_rna(pr_dict, name_to_locus, gff_dict):
    
    for chromo in pr_dict:
        for name in pr_dict[chromo]['rna']:
            loci = name_to_locus[name]
            
            lstart = loci[1]
            lstop = loci[2]
            lsign = loci[3]
            
            if name not in gff_dict:
                gff_dict[name] = {'chromo': chromo, 'sign': lsign}
            
            for region in pr_dict[chromo]['rna'][name]:
                start = pr_dict[chromo]['rna'][name][region]['start']
                stop = pr_dict[chromo]['rna'][name][region]['stop'] 
                ratios = pr_dict[chromo]['rna'][name][region]['ratios']
                                
                if start < lstart:
                    if lsign == '+':
                        if 'TSS' not in gff_dict[name]:   
                            gff_dict[name]['TSS'] = {}
                            
                        gff_dict[name]['TSS'][start] = {'ratios': ratios, 'stop':stop}
                        
                    if lsign == '-':                        
                        if 'TTS' not in gff_dict[name]:   
                            gff_dict[name]['TTS'] = {}
                            
                        gff_dict[name]['TTS'][start] = {'ratios': ratios, 'stop':stop}
                        
                if stop > lstop:
                    if lsign == '+':
                        if 'TTS' not in gff_dict[name]:   
                            gff_dict[name]['TTS'] = {}
                            
                        gff_dict[name]['TTS'][start] = {'ratios': ratios, 'stop':stop}
                        
                    if lsign == '-':
                        if 'TSS' not in gff_dict[name]:   
                            gff_dict[name]['TSS'] = {}
                            
                        gff_dict[name]['TSS'][start] = {'ratios': ratios, 'stop':stop}
                    
                if (start > lstart) and (stop < lstop):
                    if 'TBD' not in gff_dict[name]:
                        gff_dict[name]['TBD'] = {}
                        
                    gff_dict[name]['TBD'][start] = {'ratios': ratios, 'stop':stop}
                    
    return(gff_dict)
    
def process_positional_rpf(pr_dict, name_to_locus, gff_dict):
    for chromo in pr_dict:
        for name in pr_dict[chromo]['rpf']:
            loci = name_to_locus[name]
            
            lstart = loci[1]
            lstop = loci[2]
            lsign = loci[3]
            
            if name not in gff_dict:
                gff_dict[name] = {'chromo': chromo, 'sign': lsign}
            
            for region in pr_dict[chromo]['rpf'][name]:
                start = pr_dict[chromo]['rpf'][name][region]['start']
                stop = pr_dict[chromo]['rpf'][name][region]['stop'] 
                ratios = pr_dict[chromo]['rpf'][name][region]['ratios']
                                
                if start < lstart:
                    if lsign == '+':
                        if 'uORF' not in gff_dict[name]:   
                            gff_dict[name]['uORF'] = {}
                            
                        gff_dict[name]['uORF'][start] = {'ratios': ratios, 'stop':stop}
                        
                    if lsign == '-':                        
                        if 'dORF' not in gff_dict[name]:   
                            gff_dict[name]['dORF'] = {}
                            
                        gff_dict[name]['dORF'][start] = {'ratios': ratios, 'stop':stop}
                        
                if stop > lstop:
                    if lsign == '+':
                        if 'dORF' not in gff_dict[name]:   
                            gff_dict[name]['dORF'] = {}
                            
                        gff_dict[name]['dORF'][start] = {'ratios': ratios, 'stop':stop}
                        
                    if lsign == '-':
                        if 'uORF' not in gff_dict[name]:   
                            gff_dict[name]['uORF'] = {}
                            
                        gff_dict[name]['uORF'][start] = {'ratios': ratios, 'stop':stop}
                    
                if (start > lstart) and (stop < lstop):
                    if 'TBD' not in gff_dict[name]:
                        gff_dict[name]['TBD'] = {}
                        
                    gff_dict[name]['TBD'][start] = {'ratios': ratios, 'stop':stop}
                    
    return(gff_dict)
    
def process_positional_teff(pr_dict, name_to_locus, gff_dict):
    for chromo in pr_dict:
        for name in pr_dict[chromo]['teff']:
            loci = name_to_locus[name]
            
            lstart = loci[1]
            lstop = loci[2]
            lsign = loci[3]
            
            if name not in gff_dict:
                gff_dict[name] = {'chromo': chromo, 'sign': lsign}
            
            for region in pr_dict[chromo]['teff'][name]:
                start = pr_dict[chromo]['teff'][name][region]['start']
                stop = pr_dict[chromo]['teff'][name][region]['stop'] 
                ratios = pr_dict[chromo]['teff'][name][region]['ratios']
                                
                if start < lstart:
                    if lsign == '+':
                        if 'uORF' not in gff_dict[name]:   
                            gff_dict[name]['uORF'] = {}
                            
                        gff_dict[name]['uORF'][start] = {'ratios': ratios, 'stop':stop}
                        
                    if lsign == '-':                        
                        if 'dORF' not in gff_dict[name]:   
                            gff_dict[name]['dORF'] = {}
                            
                        gff_dict[name]['dORF'][start] = {'ratios': ratios, 'stop':stop}
                        
                if stop > lstop:
                    if lsign == '+':
                        if 'dORF' not in gff_dict[name]:   
                            gff_dict[name]['dORF'] = {}
                            
                        gff_dict[name]['dORF'][start] = {'ratios': ratios, 'stop':stop}
                        
                    if lsign == '-':
                        if 'uORF' not in gff_dict[name]:   
                            gff_dict[name]['uORF'] = {}
                            
                        gff_dict[name]['uORF'][start] = {'ratios': ratios, 'stop':stop}
                    
                if (start > lstart) and (stop < lstop):
                    if 'TBD' not in gff_dict[name]:
                        gff_dict[name]['TBD'] = {}
                        
                    gff_dict[name]['TBD'][start] = {'ratios': ratios, 'stop':stop}
                    
    return(gff_dict)
                
def load_positional_data(readtype, strain, replicate, chromo, experiment_object):
    path = experiment_object[readtype][strain][replicate]['normalized_locus_uid'].rsplit('/',1)[0]
    infile = ('{path}/{readtype}_{strain}_{replicate}_{chromo}_normalized_locus_uid_depth.p').format(
            path=path, readtype = readtype, strain=strain, replicate = replicate, chromo=chromo)
    temp_dict = load_pickle(infile)
    
    return(temp_dict)
    
if args.positional_regions:
    import matplotlib.pyplot as plt
    
    experiment_object_name = args.experiment_object
    experiment_object = load_pickle(experiment_object_name) 
    
    '''
    assfuck
    The idea here is that we can identify changes between samples by asking how correlated they are over regions. 
        Let's say I have a region of some size, 
    ___ problem - no idea if this works
        ___ test case: GCN4 uORFs between 1657 and 1743
            (replicate by replicate)
            
    #NB the take home seems to be that chisquare can illuminate who is different
    more easily than spearman can idenityf who is the same.
    
    #NB core statistic is chisquare
    '''
#    from scipy import stats
#    from scipy.stats import chi2_contingency
#    import statsmodels.api as sm
#    from numpy.random import normal
    outfile = 'exp'
    temp_outfile = ('{}_positional_log.tab').format(outfile)
    
#    feature_name='gff'
#    gfffile_name='C:/Gresham/Project_Carolino/metadata/saccharomyces_cerevisiae.gff'
    
    #'C:/Gresham/Project_Carolino_new/ensembl_50/Saccharomyces_cerevisiae.R64-1-1.50.gff3'
#    
  
    global_positional_dict = {}    
    
    if args.bed_file_name:
        bedfile_name = args.bed_file_name
        locus_to_name, chromo_to_locus = parse_bed_for_feature(bedfile_name)
        
    if args.gff_file_name:
        feature_name = args.feature_name
        gfffile_name = args.gff_file_name
        locus_to_name, chromo_to_locus = parse_gff_for_feature(gfffile_name, feature_name)
    
    #morf_locus_to_name, morf_chromo_to_locus = parse_gff_for_feature(gfffile_name, feature_name)
    
    '''
    #TODO: load DNA via experiment object
    #    experiment_object_name = args.experiment_object
    #    experiment_object = load_pickle(experiment_object_name)
    
    experiment_object['RNA']['DGY1657']['R1']['dna_path']
    '/scratch/ps163/Carolina_01_17_2021/depth/DGY1657_abs_depth.p'
    '''
    name_to_locus = {}
    
    for strain in experiment_object['RNA']:
        if experiment_object['RNA'][strain] != experiment_object['RNA'][strain]['R1']['anc_strain']:
            
            anc_strain = experiment_object['RNA'][strain]['R1']['anc_strain']
            anc_dna_depth = load_pickle(experiment_object['RNA'][anc_strain]['R1']['dna_path'])
            
            evo_dna_depth = load_pickle(experiment_object['RNA'][strain]['R1']['dna_path'])
            
            #dna_depth_dict = build_gene_by_dna_depth(locus_to_name, chromo_to_locus, experimental_name = 'dna_depth_by_regions', output_file = 'test')
            #for chromo in chromo_to_locus:
            #for chromo in ['I']:
            experiment_object['RNA']['DGY1657']['R1']['normalized_locus_uid']
            #
            for chromo in ['XI']:
                pr_dict = {}
                gff_dict = {}
                    
                anc_rpf_1_uid_depth = load_positional_data('RPF', anc_strain, 'R1', chromo, experiment_object)
                anc_rpf_2_uid_depth = load_positional_data('RPF', anc_strain, 'R2', chromo, experiment_object)
                
                anc_rna_1_uid_depth = load_positional_data('RNA', anc_strain, 'R1', chromo, experiment_object)
                anc_rna_2_uid_depth = load_positional_data('RNA', anc_strain, 'R2', chromo, experiment_object)                
                    
                evo_rpf_1_uid_depth = load_positional_data('RPF', strain, 'R1', chromo, experiment_object) 
                evo_rpf_2_uid_depth = load_positional_data('RPF', strain, 'R2', chromo, experiment_object) 
                
                evo_rna_1_uid_depth = load_positional_data('RNA', strain, 'R1', chromo, experiment_object) 
                evo_rna_2_uid_depth = load_positional_data('RNA', strain, 'R2', chromo, experiment_object) 
                
                positional_dna_depth_dict = make_relative_depth_dict(evo_dna_depth[chromo], anc_dna_depth[chromo])
                
                if True:
                #for chromo in chromo_to_locus:
                # locus == ('{chromo}:{start}-{stop},{sign}')
#                locus_list = chromo_to_locus[chromo]
#                
#                for loci in locus_list:
#                    print(loci)
#                    lchromo = loci[0]
#                    lstart = loci[1]
#                    lstop = loci[2]
#                    lsign = loci[3]                  
#                    locus = ('{chromo}:{start}-{stop},{sign}').format(chromo=lchromo, start=lstart, stop=lstop, sign=lsign)
#                    print(locus)
#                    name = list(locus_to_name[locus])[0]
                    
                    
                    #
                    name = 'GAP1_depth_step'
                    lchromo = 'XI'
                    lstart = 514505
                    lstop = 517504
                    lsign = '+'
#                    #    
#    #                name = 'YSR3'
#    #                lchromo = 'XI'
#    #                lstart = 534007
#    #                lstop = 535456
#    #                lsign = '-'
#    #                #        
#                    name = 'Uth1'
#                    lchromo = 'XI'
#                    lstart = 519170
#                    lstop = 520724
#                    lsign = '+'
#                    
#                    name = 'Shb17'
#                    lchromo = 'XI'
#                    lstart = 520874
#                    lstop = 521731
#                    lsign = '-'
                    
#                    print(name, locus)
    #                name = str(name)
#                    
#                    if name not in name_to_locus:
#                        name_to_locus[name] = loci
                        
                    pr_dict = pr_plot(name, lchromo, lstart, lstop, lsign,
                            anc_rpf_1_uid_depth, anc_rpf_2_uid_depth,
                            anc_rna_1_uid_depth, anc_rna_2_uid_depth,
                            evo_rpf_1_uid_depth, evo_rpf_2_uid_depth,
                            evo_rna_1_uid_depth, evo_rna_2_uid_depth,
                            positional_dna_depth_dict, pr_dict)
                    
    #                for region in pr_dict['XI']['rpf']['GAP1_step']:
    #                    print(pr_dict['XI']['rpf']['GAP1_step'][region]['start'], pr_dict['XI']['rpf']['GAP1_step'][region]['stop'])
    #                
                    #TODO - de indent and run at end
                    gff_dict = process_positional_rna(pr_dict, name_to_locus, gff_dict)
                    gff_dict = process_positional_rpf(pr_dict, name_to_locus, gff_dict)
                    gff_dict = process_positional_teff(pr_dict, name_to_locus, gff_dict)
                    
        print(gff_dict.keys())
                    
        for name in gff_dict:
            for feature in gff_dict[name]:
                if feature == 'TSS':
                    for start in gff_dict[name][feature]:
                        pass
                        #fuck
        #eval_regions(nt_map, heat_map)
    
def count_uid_for_feature(sample_name, chromo, readtype, isnorm, 
                          locus_uid_depth_file_name, locus_list,
                          expression_dict, key_dict, name_to_locus):
    
    sample_base = load_pickle(locus_uid_depth_file_name)
    
    #TODO currently the normalized dictionary has an extra level 
    # with the chromo name - probably could get rid of that.
    
    if isnorm == 'unnormalized':
        sample = sample_base
    else:
        sample = sample_base[chromo]
        
    print('count_uid_for_feature', locus_uid_depth_file_name)

    for locus in locus_list:
        ch, start, stop, sign = locus
        locus_depths = set()
                    
        for nt in range(start, stop+1):

            if nt in sample[sign]:
                for each in sample[sign][nt]:
                    locus_depths.add(each)
                                           
        key = ('{}:{}-{},{}').format(ch, start, stop, sign)
        nameset = locus_to_name[key]
        
        for name in nameset:
            if name not in key_dict:
                key_dict[name] = {}
                
            key_dict[name][sample_name] = len(locus_depths)
                                            
            if name not in expression_dict:  
                expression_dict[name] = {}
                
            if sample_name not in expression_dict[name]:
                expression_dict[name][sample_name] = {}

            if readtype not in expression_dict[name][sample_name]:
                expression_dict[name][sample_name][readtype] = {}
                
            if isnorm not in expression_dict[name][sample_name][readtype]:
                expression_dict[name][sample_name][readtype][isnorm] = 0
            
            expression_dict[name][sample_name][readtype][isnorm] = len(locus_depths)
                                        
            if name not in name_to_locus:
                name_to_locus[name] = key
                
    return(key_dict, name_to_locus)
    
def populate_expression_dict(locus_to_name):
    
    experiment_object_name = args.experiment_object
    experiment_object = load_pickle(experiment_object_name)
    
    expression_dict = {}
    key_dict = {}
    name_to_locus = {}
    
    for readtype in ['RPF','RNA']:
        for strain in experiment_object[readtype]:
            for replicate in experiment_object[readtype][strain]:
                pickle_path = experiment_object[readtype][strain][replicate]['output_path']
                
                if 'ror_sample_names' not in experiment_object[readtype][strain][replicate]:
                    experiment_object[readtype][strain][replicate]['ror_sample_names'] = set()
                    
                for chromo in chromo_set:
                    locus_list = chromo_to_locus[chromo]
                    
                    for isnorm in ['unnormalized', 'normalized']:
                        locus_uid_depth_file_name = ('{pickle_path}/{readtype}_{strain}_{replicate}_{chromo}_{isnorm}_locus_uid_depth.p').format(
                                pickle_path = pickle_path, readtype = readtype, strain = strain, 
                                replicate = replicate, chromo = chromo, isnorm = isnorm)
                        
                        sample_name =('{readtype}_{strain}_{replicate}').format(
                                readtype = readtype, strain = strain, replicate = replicate)
                        
                        #experiment_object[readtype][strain][replicate]['ror_sample_names'].add(sample_name)
                                            
                        key_dict, name_to_locus = count_uid_for_feature(sample_name, chromo, readtype, isnorm, 
                                                                        locus_uid_depth_file_name, locus_list,
                                                                        expression_dict, key_dict, name_to_locus)
                        
        
                    
        ntl_df = pd.DataFrame.from_dict(key_dict, orient='index')
        df_name = ('{}_gene_locus.csv').format(readtype)
        ntl_df.to_csv(df_name)
                     
        key_df = pd.DataFrame.from_dict(key_dict, orient='index')
        df_name = ('{}_gene_by_gene_cRNA.csv').format(readtype)
        key_df.to_csv(df_name)
                
        corr_df = key_df.corr('spearman')
        corr_df.head()
        df_name = ('{}_sample_correlation_cRNA.csv').format(readtype)        
        corr_df.to_csv(df_name)
                    
        pickle_name = ('{}_{}_exp_abun_by_gene_dict.p').format(args.output_file, readtype)
        pickle.dump(key_dict, open(pickle_name, 'wb'))
        
        pickle_name = ('{}_{}_proto_expression.p').format(args.output_file, readtype)
        pickle.dump(expression_dict, open(pickle_name, 'wb'))
        
    pickle.dump(experiment_object, open(experiment_object_name, 'wb'))
                            
    return(expression_dict)
    
def adjust_expression_by_depth(expression_dict, dna_depth_dict):
    switch_readtype = {'RPF':'RNA','RNA':'RPF'}
    
    #expression_dict[name][sample_name][readtype]
    
    experiment_object_name = args.experiment_object
    experiment_object = load_pickle(experiment_object_name)
        
    #experiment_object[readtype][strain][replicate]['ror_sample_names']
#    for readtype in ['RPF', 'RNA']:
#        for sample_name in experiment_object[readtype]:
#            for replicate in experiment_object[readtype][sample_name]:
#                uid = experiment_object[sample_type][sample_name][replicate]['uid']
#                ror_sample_names = experiment_object[readtype][strain][replicate]['ror_sample_names']
#                
#                for ror_name in ror_sample_names:
#                    if ror_name not in sample_lookup:
#                        sample_lookup[ror_name] = {'uid':uid}
    
    #expression_dict[name][sample_name][readtype][isnorm] = len(locus_depths)
    missing_set = set()
    
    for name in expression_dict:
        #print('name', name)
        for sample_name in expression_dict[name]:
            strain_name = sample_name.split('_')[1]
            #print('sample_name', sample_name)
            #print('dna_depth', type(dna_depth_dict), len(dna_depth_dict))

            if name not in dna_depth_dict:
                missing_set.add(name)
                
            
            if name in dna_depth_dict:
                #uid = sample_lookup[ror_name]['uid']
                #ans_sample_name = experiment_object[sample_type][sample_name]['R1']['anc_strain']
                
                for replicate in experiment_object['RPF'][strain_name]:
                    anc_strain_name = experiment_object['RPF'][strain_name][replicate]['anc_strain']
                    anc_sample_name = sample_name.replace(strain_name, anc_strain_name)
                    
                    readtype = list(expression_dict[name][sample_name].keys())[0]
                    
                    other_readtype_name = sample_name.replace(readtype, switch_readtype[readtype])
                    other_anc_readtype_name = anc_sample_name.replace(readtype, switch_readtype[readtype])
                    
                    if strain_name not in dna_depth_dict[name]:
                        print('missing name from dna_depth_dict', name)
                
                    if strain_name in dna_depth_dict[name]:
                        obs_dna_depth = (dna_depth_dict[name][strain_name])
                        anc_dna_depth = (dna_depth_dict[name][anc_strain_name])
                        
                        if anc_dna_depth != 0:
                            rel_dna_depth = (obs_dna_depth)/(anc_dna_depth)
                        else:
                            rel_dna_depth = (obs_dna_depth)
                                                
                        for isnorm in ['unnormalized','normalized']:
                            #if 'RPF' == readtype:
                            read_count = expression_dict[name][sample_name][readtype][isnorm]
                            anc_read_count = expression_dict[name][anc_sample_name][readtype][isnorm]
                            
                            if readtype not in expression_dict[name][other_readtype_name]:
                                expression_dict[name][other_readtype_name][readtype] = {}

                            expression_dict[name][other_readtype_name][readtype][isnorm] = read_count
                            
                            if readtype not in expression_dict[name][other_anc_readtype_name]:
                                expression_dict[name][other_anc_readtype_name][readtype] = {}
                                
                            expression_dict[name][other_anc_readtype_name][readtype][isnorm] = anc_read_count
#
#                            if 'RNA' == readtype:
#                                rna_count = expression_dict[name][sample_name][readtype][isnorm]
#                                anc_rna_count = expression_dict[name][anc_sample_name][readtype][isnorm]
#                                
#                                expression_dict[name][other_readtype_name][readtype][isnorm] = rna_count
#                                expression_dict[name][other_anc_readtype_name][readtype][isnorm] = anc_rna_count
                            
                            for each in ['obs_DNA', 'anc_dna', 'rel_DNA']:
                                if each not in expression_dict[name][sample_name]:
                                    expression_dict[name][sample_name][each] = {}
 
                            expression_dict[name][sample_name]['obs_DNA'][isnorm] = obs_dna_depth
                            expression_dict[name][sample_name]['anc_dna'][isnorm] = anc_dna_depth
                            expression_dict[name][sample_name]['rel_DNA'][isnorm] = rel_dna_depth
                            
    for name in missing_set:
        print('Warning: name in expression but absent from dna_depth: ', name)
                                                                           
    pickle_name = ('{}_expression_dict.p').format(args.output_file)
    pickle.dump(expression_dict, open(pickle_name, 'wb'))
    
    experiment_object['expression_dict'] = pickle_name
    pickle.dump(experiment_object, open(experiment_object_name, 'wb'))
    
    return(expression_dict)
    
#if args.reads_over_regions:
if args.locus_depth:
    feature_name = args.feature_name
        
    #This presumes regions are well defined - here we'll be using CDS 
    if args.gff_file_name:
        gfffile_name = args.gff_file_name
        locus_to_name, chromo_to_locus = parse_gff_for_feature(gfffile_name, feature_name)
            
    if args.bed_file_name:
        bedfile_name = args.bed_file_name
        locus_to_name, chromo_to_locus = parse_bed_for_feature(bedfile_name, feature_name)

    dna_depth_dict = build_gene_by_dna_depth(locus_to_name, chromo_to_locus)
    #print(len(dna_depth_dict), type(dna_depth_dict))
    
    pickle_name = ('{}_dna_depth_dict.p').format(args.output_file)
    pickle.dump(dna_depth_dict, open(pickle_name, 'wb'))
                   
if args.locus_expression:
    feature_name = args.feature_name
    
    experiment_object_name = args.experiment_object
    experiment_object = load_pickle(experiment_object_name)
    
    dna_depth_dict_name = experiment_object['dna_depth_by_gene']
    dna_depth_dict = load_pickle(dna_depth_dict_name)
    
    #This presumes regions are well defined - here we'll be using CDS 
    if args.gff_file_name:
        gfffile_name = args.gff_file_name
        locus_to_name, chromo_to_locus = parse_gff_for_feature(gfffile_name, feature_name)
            
    if args.bed_file_name:
        bedfile_name = args.bed_file_name
        locus_to_name, chromo_to_locus = parse_bed_for_feature(bedfile_name, feature_name)
        
    expression_dict = populate_expression_dict(locus_to_name)

    pickle_name = ('{}_expression_dict.p').format(args.output_file)
    pickle.dump(expression_dict, open(pickle_name, 'wb'))
    
    experiment_object['expression_dict']=pickle_name
    pickle.dump(experiment_object, open(experiment_object_name, 'wb'))
    
if args.adjust_expression:
    
    experiment_object_name = args.experiment_object
    experiment_object = load_pickle(experiment_object_name)
    
    dna_depth_dict_name = experiment_object['dna_depth_by_gene']
    dna_depth_dict = load_pickle(dna_depth_dict_name)
    
    expression_dict_name = experiment_object['expression_dict']
    expression_dict = load_pickle(expression_dict_name)
    
    #
    
    expression_dict = adjust_expression_by_depth(expression_dict, dna_depth_dict)
    
    pickle_name = ('{}_expression_dict.p').format(args.output_file)
    pickle.dump(expression_dict, open(pickle_name, 'wb'))
    
    '''
    now compare
    '''      
    
if args.calculate_expression_profile:
    experiment_object_name = args.experiment_object
    experiment_object = load_pickle(experiment_object_name)
    
    expression_dict_name = experiment_object['expression_dict']
    expression_dict = load_pickle(expression_dict_name)
    
    outname = args.output_file
    
    temp_log_file = open('temp_dna_depth.log','w')
    
    comparison_name_dict = {}
        
    for readtype in ['RPF','RNA']:
        #print(readtype)
        for strain in experiment_object[readtype]:
            exp_list = []
            anc_list = []
            #print(strain)
            for replicate in experiment_object[readtype][strain]:
                #print(replicate)
                exp_uid = experiment_object[readtype][strain][replicate]['uid']
                exp_list.append(exp_uid)
                
                anc_strain = experiment_object[readtype][strain][replicate]['anc_strain']
                anc_uid = ('{}_{}_{}').format(readtype, anc_strain, replicate)
                anc_list.append(anc_uid)
                
            if strain != anc_strain:
                
                comparison_name = ('{}_v_{}').format(min(strain, anc_strain), max(strain, anc_strain))
                print(comparison_name)
                
                if comparison_name not in comparison_name_dict:                    
                    comparison_name_dict[comparison_name] = [anc_list, exp_list]
            
##    comparison_name_dict = {'un_1657_v_1726':[['un_1657_R1', 'un_1657_R2'],['un_1726_R1', 'un_1726_R2']],
##                             'n_1657_v_1726':[['n_1657_R1', 'n_1657_R2'],['n_1726_R1', 'n_1726_R2']],
##                             'un_1657_v_1728':[['un_1657_R1', 'un_1657_R2'],['un_1728_R1', 'un_1728_R2']],
##                             'n_1657_v_1728':[['n_1657_R1', 'n_1657_R2'],['n_1728_R1', 'n_1728_R2']],
##                             'un_1657_v_1735':[['un_1657_R1', 'un_1657_R2'],['un_1735_R1', 'un_1735_R2']],
##                             'n_1657_v_1735':[['n_1657_R1', 'n_1657_R2'],['n_1735_R1', 'n_1735_R2']],
##                             'un_1657_v_1741':[['un_1657_R1', 'un_1657_R2'],['un_1741_R1', 'un_1741_R2']],
##                             'n_1657_v_1741':[['n_1657_R1', 'n_1657_R2'],['n_1741_R1', 'n_1741_R2']],
##                             'un_1657_v_1743':[['un_1657_R1', 'un_1643_R2'],['un_1743_R1', 'un_1743_R2']],
##                             'n_1657_v_1743':[['n_1657_R1', 'n_1643_R2'],['n_1743_R1', 'n_1743_R2']]}
#    
#    comparison_name_dict = {'n_1657_v_1726':[['n_1657_R1', 'n_1657_R2'],['n_1726_R1', 'n_1726_R2']],
#                             'n_1657_v_1728':[['n_1657_R1', 'n_1657_R2'],['n_1728_R1', 'n_1728_R2']],
#                             'n_1657_v_1735':[['n_1657_R1', 'n_1657_R2'],['n_1735_R1', 'n_1735_R2']],
#                             'n_1657_v_1741':[['n_1657_R1', 'n_1657_R2'],['n_1741_R1', 'n_1741_R2']],
#                             'n_1657_v_1743':[['n_1657_R1', 'n_1657_R2'],['n_1743_R1', 'n_1743_R2']]}
    
    eval_exp_dict = {}
    ct = 0
    total = len(expression_dict)
    
    for name in expression_dict:
        ct+=1
        
        if ct % total == 10:
            outline = ('Processing {name}\t {pct:.2f}').format(name=name, pct=ct/total)
            print(outline)
        
        for comparison_name in comparison_name_dict:
            for isnorm in ['unnormalized','normalized']:
                pairs = comparison_name_dict[comparison_name]
                ancestor_pair = pairs[0]
                exp_pair = pairs[1]
                                
                if 'anc_dna' in expression_dict[name][pairs[0][0]]:
                    anc_dna = (expression_dict[name][pairs[0][0]]['anc_dna'][isnorm])
                    obs_dna = (expression_dict[name][pairs[1][0]]['obs_DNA'][isnorm])
                    
                    if (anc_dna < 1):
                        anc_dna = round(anc_dna,0)
                        
                    if (obs_dna < 1):
                        obs_dna = round(obs_dna,0)
                    
                    if anc_dna != 0:                    
                        rel_dna = round(obs_dna/anc_dna,0)
                        
                    else:
                        rel_dna = round(obs_dna,0)
                        
                    #add subroutine to correct for false zeros
                    if rel_dna == 0:
                        anc_dna = (expression_dict[name][pairs[0][0]]['anc_dna'][isnorm])
                        obs_dna = (expression_dict[name][pairs[1][0]]['obs_DNA'][isnorm])
                            
                        if anc_dna != 0:
                            rel_dna = obs_dna/anc_dna
                        else:
                            rel_dna = obs_dna
                        
        #            anc_dna = (expression_dict[name][pairs[1][0]]['anc_dna'])
        #            obs_dna = (expression_dict[name][pairs[1][0]]['obs_DNA'])
                    
                    #TODO - we assume all genes in ancestor are ~1, how accurate is this?
                    #currently - mostly accurate although there are clusters (see supplemental)
                    #
                    if (anc_dna <= 0.5):
                        outline = ('{}\t{}\tlow\n').format(name, anc_dna)
                        temp_log_file.write(outline)
                        
                    if (anc_dna >= 1.5):
                        outline = ('{}\t{}\thigh\n').format(name, anc_dna)
                        temp_log_file.write(outline)            
                
                    arpf_1 = expression_dict[name][pairs[0][0]]['RPF'][isnorm]
                    arpf_2 = expression_dict[name][pairs[0][1]]['RPF'][isnorm]
                    arna_1 = expression_dict[name][pairs[0][0]]['RNA'][isnorm]
                    arna_2 = expression_dict[name][pairs[0][1]]['RNA'][isnorm]
                    # TODO:
                    # alternatively we can back calculate the expected RPF using the
                    # ancestral tEff and observed RNA
                    # eg: erpf_1 = round(orna_ * atEff_1, 0)
                    #atEff_1 = arpf_1/max(arna_1,1)
                    #atEff_2 = arpf_2/max(arna_2,1)
                    
                    orpf_1 = expression_dict[name][pairs[1][0]]['RPF'][isnorm]
                    orpf_2 = expression_dict[name][pairs[1][1]]['RPF'][isnorm]
                    orna_1 = expression_dict[name][pairs[1][0]]['RNA'][isnorm]
                    orna_2 = expression_dict[name][pairs[1][1]]['RNA'][isnorm]
                    
                    erna_1 = round(arna_1*rel_dna, 0)
                    erna_2 = round(arna_2*rel_dna, 0)
                    erpf_1 = round(arpf_1*rel_dna, 0)
                    erpf_2 = round(arpf_2*rel_dna, 0)
                                
                    eval_exp_dict = stats_on_counts(name, comparison_name, isnorm, anc_dna, obs_dna, rel_dna,
                            orpf_1, orpf_2, orna_1, orna_2,
                            erpf_1, erpf_2, erna_1, erna_2,
                            arpf_1, arpf_2, arna_1, arna_2,
                            eval_exp_dict)
            
    output_exp_stats(eval_exp_dict)
                    
    temp_log_file.close()
    
def populate_trends(strain, gene, istype, readtype, is_sig, is_eff, strain_exp):
    '''TODO 
    FUCK FIX THIS
    '''
    
    if readtype == 'rpf':
        orpf_1 = eval_exp_dict[strain][gene]['oRPF1']
        orpf_2 = eval_exp_dict[strain][gene]['oRPF2']
        arpf_1 = eval_exp_dict[strain][gene]['aRPF1']*eval_exp_dict[strain][gene]['rDNA']
        arpf_2 = eval_exp_dict[strain][gene]['aRPF2']*eval_exp_dict[strain][gene]['rDNA']
        obs_mean, exp_mean, l_eff, l_pval, process = expression_level_criteria(orpf_1, orpf_2, arpf_1, arpf_2, 6571)
        
        if process:
            if l_eff > 1:
                strain_exp[strain][istype][readtype]['up'].append(gene)
            else:
                strain_exp[strain][istype][readtype]['down'].append(gene)
                
        else:
            strain_exp[strain][istype][readtype]['ns'].append(gene)
            
        strain_exp[strain][istype][readtype]['total'].append(gene)
        
        return(strain_exp)
        
    else:
        if eval_exp_dict[strain][gene][is_sig]:
            if eval_exp_dict[strain][gene][is_eff] > 1:
                strain_exp[strain][istype][readtype]['up'].append(gene)
            else:
                strain_exp[strain][istype][readtype]['down'].append(gene)
                
        else:
            strain_exp[strain][istype][readtype]['ns'].append(gene)
            
        strain_exp[strain][istype][readtype]['total'].append(gene)
        
        return(strain_exp)
    
def simulator(uorf_hit, other_hit, total_set, observed, runs=10000):    
    result_list = []
    
    for iteration in range(runs):
        uorf_set = set()
        other_set = set()
        
        for gene in range(total_set):
            if (random.random()) <= (uorf_hit/total_set):
                uorf_set.add(gene)
                
            if (random.random()) <= (other_hit/total_set):
                other_set.add(gene)
                
             
        result_list.append(len(other_set.intersection(uorf_set)))  
        
    ct = 0
    
    for result in result_list:
        if result >= observed:
            ct+=1

    median_result = np.median(result_list)
    
    if median_result != 0:
        fold = observed/median_result
    else:
        fold = observed
        
    pval = ct/runs
    
#    outline = ('fold-difference: {fold}\tpvalue: {pval}\nobs: {observed}\nexp: {median_result}').format(fold=fold, pval=pval, 
#              observed=observed, median_result=median_result)
#    #print(outline)
    
    return(fold, pval)
    

#TODO - is this still needed?
if args.expression_trends:
    #import random
    #import numpy as np
    ''' Here we read in significant regulation and count up trends inside and outside of the CNV regions
        for this we'll need gene names that are involved in the CNVs ... 
    '''   
    
    filename = ('C:/Gresham/Project_Carolino/supplemental/None_normalized_eval_exp_dict.p')
    file = open(filename,'rb')
    eval_exp_dict = pickle.load(file)
    file.close()
    
    lookup_cnv_genes = {'n_1657_v_1726': ['YKR010C','YKR011C','YKR012C','YKR013W','YKR014C','YKR015C',
	'YKR016W','YKR017C','YKR018C','YKR019C','YKR020W','YKR021W','YKR022C','YKR023W',
	'YKR024C','YKR025W','YKR026C','YKR027W','YKR028W','YKR029C','YKR030W','YKR031C',
	'YKR033C','YKR034W','YKR035W-A','YKR036C','YKR037C','YKR038C','YKR039W','YKR040C',
	'YKR041W','YKR042W','YKR043C','YKR044W','YKR045C','YKR046C','YKR047W','YKR048C',
	'YKR049C','YKR050W','YKR051W','YKR052C','YKR053C','YKR054C','YKR055W','YKR056W',
	'YKR057W','YKR058W','YKR059W','YKR060W','YKR061W','YKR062W','YKR063C','YKR064W',
	'YKR065C','YKR066C','YKR067W','YKR068C','YKR069W','YKR070W','YKR071C','YKR072C',
	'YKR074W','YKR075C','YKR075W-A','YKR076W','YKR077W','YKR078W','YKR079C','YKR080W',
	'YKR081C','YKR082W','YKR083C','YKR084C','YKR085C','YKR086W','YKR087C','YKR088C',
	'YKR089C','YKR090W','YKR091W','YKR092C','YKR093W','YKR094C','YKR095W','YKR095W-A','YKR096W','YKR097W',
	'YKR098C', 'YKR099W', 'YKR100C', 'YKR101W', 'YKR102W', 'YKR103W', 'YKR104W', 'YKR105C', 'YKR106W'],
        'n_1657_v_1728': [],
        'n_1657_v_1735': ['YKR021W','YKR022C','YKR023W','YKR024C','YKR025W','YKR026C',
	'YKR027W','YKR028W','YKR029C','YKR030W','YKR031C','YKR032W','YKR033C','YKR034W',
	'YKR035C','YKR035W-A','YKR036C','YKR037C','YKR038C','YKR039W','YKR040C','YKR041W',
	'YKR042W','YKR043C','YKR044W','YKR045C','YKR046C','YKR047W','YKR048C','YKR049C',
	'YKR050W','YKR051W','YKR052C','YKR053C','YKR054C','YKR055W','YKR056W','YKR057W',
	'YKR058W','YKR059W','YKR060W','YKR061W','YKR062W','YKR063C','YKR064W','YKR065C',
	'YKR066C','YKR067W','YKR068C','YKR069W','YKR070W','YKR071C','YKR072C','YKR073C',
	'YKR074W','YKR075C','YKR075W-A','YKR076W','YKR077W','YKR078W','YKR079C','YKR080W',
	'YKR081C','YKR082W','YKR083C','YKR084C','YKR085C','YKR086W','YKR087C','YKR088C',
	'YKR089C','YKR090W','YKR091W','YKR092C','YKR093W','YKR094C','YKR095W','YKR095W-A',
	'YKR096W','YKR097W','YKR098C','YKR099W','YKR100C','YKR101W'],
        'n_1657_v_1741': ['YKR029C','YKR030W','YKR031C','YKR032W','YKR033C','YKR034W',
	'YKR035C','YKR035W-A','YKR036C','YKR037C','YKR038C','YKR039W','YKR040C','YKR041W',
	'YKR042W','YKR043C','YKR044W','YKR045C','YKR046C','YKR047W','YKR048C','YKR049C','YKR050W'],
        'n_1657_v_1743': ['YKR001C','YKR002W','YKR003W','YKR004C','YKR005C','YKR006C',
	'YKR007W','YKR008W','YKR009C','YKR010C','YKR011C','YKR012C','YKR013W','YKR014C',
	'YKR015C','YKR016W','YKR017C','YKR018C','YKR019C','YKR020W','YKR021W','YKR022C',
	'YKR023W','YKR024C','YKR025W','YKR026C','YKR027W','YKR028W','YKR029C','YKR030W',
	'YKR031C','YKR032W','YKR033C','YKR034W','YKR035C','YKR035W-A','YKR036C','YKR037C',
	'YKR038C','YKR039W','YKR040C','YKR041W','YKR042W','YKR043C','YKR044W','YKR045C',
	'YKR046C','YKR047W','YKR048C','YKR049C','YKR050W','YKR051W','YKR052C','YKR053C',
	'YKR054C','YKR055W','YKR056W','YKR057W','YKR058W','YKR059W','YKR060W','YKR061W',
	'YKR062W','YKR063C','YKR064W','YKR065C','YKR066C','YKR067W','YKR068C','YKR069W',
	'YKR070W','YKR071C','YKR072C','YKR073C','YKR074W','YKR075C','YKR075W-A','YKR076W',
	'YKR077W','YKR078W','YKR079C','YKR080W','YKR081C','YKR082W','YKR083C','YKR084C',
	'YKR085C','YKR086W','YKR087C','YKR088C','YKR089C','YKR090W','YKR091W','YKR092C',
	'YKR093W','YKR094C','YKR095W','YKR095W-A','YKR096W']}
    
    for gene in eval_exp_dict['n_1657_v_1728']:
        if gene[:2] == 'YK':
            lookup_cnv_genes['n_1657_v_1728'].append(gene)

    strain_exp = {}
    
    for strain in lookup_cnv_genes:
        
        cnv_list = lookup_cnv_genes[strain]
        
        if strain not in strain_exp:
            strain_exp[strain] = {
                    'CNV':{
                            'rna':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    },
                            'rpf':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    },
                            'teff':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    }
                            },
                    'CNN':{
                            'rna':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    },
                            'rpf':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    },
                            'teff':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    }
                            },
                    'alt_CNV':{
                            'rna':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    },
                            'rpf':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    },
                            'teff':{
                                    'up':[],'down':[],'ns':[],'total':[]
                                    }
                            },
                            }
                            
            
        for gene in eval_exp_dict[strain]:
            rdna = eval_exp_dict[strain][gene]['rDNA']
            
            if gene in cnv_list:
                istype = 'CNV'
            else:
                if eval_exp_dict[strain][gene]['rDNA'] == 1:
                    istype = 'CNN'
                else:
                    istype = 'alt_CNV'
                
            readtype = 'rna'
            is_sig = 'RNA_sig'
            is_eff = 'RNA_eff'
            strain_exp = populate_trends(strain, gene, istype, readtype, is_sig, is_eff, strain_exp)
            
            readtype = 'rpf'
            is_sig = 'RPF_sig'
            is_eff = 'RPF_eff'
            strain_exp = populate_trends(strain, gene, istype, readtype, is_sig, is_eff, strain_exp)

            readtype = 'teff'
            is_sig = 'tEff_sig'
            is_eff = 'tEff_eff'
            strain_exp = populate_trends(strain, gene, istype, readtype, is_sig, is_eff, strain_exp)

                
    filename = ('C:/Gresham/Project_Carolino/supplemental/corrected_type_counts.txt')
    tempfile = open(filename, 'w')
    header = ('#strain\treadtype\tistype_query\tistype_background\tdirection\tquery\tqt\tqqt\tbackground\tbt\tbbt\teff\tpval\n')
    tempfile.write(header)
    
    #strain_exp['n_1657_v_1726']['alt_CNV']
    
    istype_list = list(strain_exp[strain].keys())
    readtype_list = ['rna', 'rpf', 'teff']
    direction_list = ['up','down','ns']
        
    for strain in strain_exp:
        for readtype in readtype_list:
            combo_list = set()
            for istype_query in istype_list:
                for istype_background in istype_list:
                    if istype_query != istype_background:
                        istype_combo = ('{}_{}').format(min([istype_query,istype_background]),max([istype_query,istype_background]))
                        
                        if istype_combo not in combo_list:
                            combo_list.add(istype_combo)
                            
                            for direction in direction_list:
                                query = len(strain_exp[strain][istype_query][readtype][direction])
                                query_total = len(strain_exp[strain][istype_query][readtype]['total'])
                                
                                background = len(strain_exp[strain][istype_background][readtype][direction])
                                background_total = len(strain_exp[strain][istype_background][readtype]['total'])
                                
                                qt = (query_total-query)
                                bt = (background_total-background)
                                
                                if (query_total) > 20 and (background_total) > 20:
                                    _no, pval = stats.fisher_exact([[query, qt], [background, bt]])
                                    #pval *= correction
                                    eff = (query / max(qt, 1))/(max(background, 1) / max(bt, 1))
                                    outline = ('{strain}\t{readtype}\t{istype_query}\t{istype_background}\t{direction}\t'
                                               '{query}\t{qt}\t{qqt}\t{background}\t{bt}\t{bbt}\t{eff}\t{pval}\n').format(
                                                       strain=strain, readtype=readtype, istype_query=istype_query, 
                                                       istype_background=istype_background, direction=direction,
                                                       query=query, qt=qt, qqt=(query/max(qt,1)),
                                                       background=background, bt=bt, bbt=(background/max(bt,1)),
                                                       eff=eff, pval=pval)
                                    tempfile.write(outline)
                                    
    tempfile.close()
    
                    
    filename = ('C:/Gresham/Project_Carolino/supplemental/corrected_readtype_counts.txt')
    tempfile = open(filename, 'w')
    header = ('#strain\tistype\treadtype_one\tdirection_one\treadtype_two\tdirection_two\tq1\tq2\tq12\tquery_total\tb1\tb2\tb12\tbackground_total\tquery_eff\tquery_pval\tbackground_eff\tbackground_pval\n')
    tempfile.write(header)
    
    for strain in strain_exp:
        for istype in istype_list:
            readtype_combo_list = set()
            for readtype_one in readtype_list:
                for readtype_two in readtype_list:
                    if readtype_one != readtype_two:
                        readtype_combo = ('{}_{}').format(min([readtype_one, readtype_two]),max([readtype_one, readtype_two]))
                        
                        if readtype_combo not in combo_list:
                            readtype_combo_list.add(istype_combo)
                            direction_combo_list = set()
                            
                            for direction_one in direction_list:
                                for direction_two in direction_list:
                                    query_one = set(strain_exp[strain][istype][readtype_one][direction_one])
                                    query_two = set(strain_exp[strain][istype][readtype_two][direction_two])
                                    query_total = len(set(strain_exp[strain][istype][readtype_two]['total']))
                                    
                                    background_one = set(strain_exp[strain]['CNN'][readtype_one][direction_one])
                                    background_two = set(strain_exp[strain]['CNN'][readtype_two][direction_two])
                                    background_total = len(set(strain_exp[strain]['CNN'][readtype_two]['total']))
        
                                    qt = len(query_one.intersection(query_two))
                                    bt = len(background_one.intersection(background_two))
                                    
                                    print(len(query_one), len(query_two), query_total, (qt))

                                    query_eff, query_pval = simulator(len(query_one), len(query_two), query_total, (qt), runs=1000)
#                                    background_eff, background_pval = simulator(len(background_one), len(background_two), background_total, (bt), runs=10000)
                                    background_eff=1
                                    background_pval=1
                                    #pval *= correction
                                    eff = (query / max(qt, 1))/(max(background, 1) / max(bt, 1))
                                    outline = ('{strain}\t{istype}\t{readtype_one}\t{direction_one}\t'
                                               '{readtype_two}\t{direction_two}\t'
                                               '{q1}\t{q2}\t{q12}\t{query_total}\t'
                                               '{b1}\t{b2}\t{b12}\t{background_total}\t'
                                               '{query_eff}\t{query_pval}\t{background_eff}\t{background_pval}\n').format(
                                                       strain=strain, istype=istype, readtype_one=readtype_one, 
                                                       readtype_two=readtype_two, direction_one=direction_one, direction_two=direction_two,
                                                       q1=len(query_one), q2=len(query_two), q12=qt,
                                                       b1=len(background_one), b2=len(background_two), b12=bt,
                                                       query_eff=query_eff, query_pval=query_pval, 
                                                       query_total=query_total, background_total=background_total,
                                                       background_eff=background_eff, background_pval=background_pval)
                                    tempfile.write(outline)
                                    print(outline)
                                    
    tempfile.close()

        
    """
    infile = open('C:/Gresham/Project_Carolino/supplemental/corrected_differences_all_calls.log')
    
    for line in infile:
        '''
        gene	anc_dna_depth	obs_DNA_depth	rel_DNA_depth	
        obs_RPF_1	obs_RPF_2	obs_RNA_1	obs_RNA_2	
        ans_RPF_1	ans_RPF_2	ans_RNA_1	ans_RNA_2	
        exp_RPF_1	exp_RPF_2	exp_RNA_1	exp_RNA_2	
        obs_1_tEff	obs_2_tEff	exp_1_tEff	exp_2_tEff	
        obs_mean_RPF	obs_mean_RNA	exp_mean_RPF	exp_mean_RNA
        _pval	RPF_eff	
        RNA_pval	RNA_eff	
        tEff_pval	tEff_eff	
        RNA_sig	RPF_sig	tEff_sig	
        strain
        '''
        
        if 'gene' not in line:
            (gene, anc_dna_depth, obs_DNA_depth. rel_DNA_depth,	
             obs_RPF_1, obs_RPF_2, obs_RNA_1, obs_RNA_2,
             ans_RPF_1, ans_RPF_2, ans_RNA_1, ans_RNA_2,
             exp_RPF_1, exp_RPF_2, exp_RNA_1, exp_RNA_2,
             obs_1_tEff, obs_2_tEff, exp_1_tEff, exp_2_tEff, 
             obs_mean_RPF, obs_mean_RNA, exp_mean_RPF, exp_mean_RNA,
             RPF_pval, RPF_eff, RNA_pval, RNA_eff, tEff_pval, tEff_eff,
             RNA_sig, RPF_sig, tEff_sig, strain) = line.split('\t')
    """       
        
    
if args.process_sam:
    
    '''
    XII	451158	468990	rDNA	0	.
    Mito	0	85779	Mito	0	.
    '''
    if args.filter_regions:
        regions_to_filter = build_regions_to_filter(args.filter_regions)
    else:
        regions_to_filter = {}
        
    '''
    read in and convert to pickles
    save pickle names for downsampling
    '''
    
    '''
    map_file format:
    #
    https://drive.google.com/file/d/1GlBsGQGeXb7QIJssIoV_JvbwDb2bJt8A/view?usp=sharing
    '''
    
    map_object = build_pickle_map(args.map_file)
    ''' map_object
    map_object[sample_type][sample_name]['input'] = original_path
    map_object[sample_type][sample_name]['output'] = output_name
    '''
    
    log_file_name = ('{}_process_sam.log').format(args.output_file.split('.')[0])
    log_file = open(log_file_name, 'w')
    
    header = ('#uid\tsample_name\tsample_type\tinput_path\output_path\taligned_read_ct\n')
    log_file.write(header)
    
    run_depth = {}
    #
    for sample_type in ['RNA', 'RPF']:
        for sample_name in map_object[sample_type]:
            for replicate in map_object[sample_type][sample_name]:
                input_path = map_object[sample_type][sample_name][replicate]['obs_path']
                output_path = map_object[sample_type][sample_name][replicate]['output_path']
                uid = map_object[sample_type][sample_name][replicate]['uid']
                reverse = map_object[sample_type][sample_name][replicate]['reverse_strand']
                
                output = ('{}{}').format(output_path, uid)
                
                aligned_read_ct = parse_sam_file(input_path, regions_to_filter, output, )
                
                outline = ('{uid}\t{sample_name}\t{sample_type}\t{input_path}\t{output_path}\t{aligned_read_ct}\n').format(
                        uid = uid, sample_name = sample_name, sample_type = sample_type, 
                        input_path = input_path, output_path = output_path,
                        aligned_read_ct = aligned_read_ct)
                log_file.write(outline)
                
                print(outline)
                
                if aligned_read_ct <= 6000:
                    print('shallow sample, fewer reads than genes')
                    print(sample_name)
                    
                    map_object[sample_type][sample_name][replicate]['notes'].append('shallow original sample, fewer reads than genes')
                            
                map_object[sample_type][sample_name][replicate]['aligned_read_ct'] = aligned_read_ct
                            
    log_file.close()
    
    #turn map file into experiment_object
    pickle_name = ('{}').format(args.experiment_object)
    pickle.dump(map_object, open(pickle_name, 'wb'))
    
if args.normalize_reads:
    
    pickle_path = args.output_file.split('.')[0]
    
    log_file_name = ('{}_normalize_reads.log').format(args.output_file.split('.')[0])
    log_file = open(log_file_name, 'w')
    
    header = ('#sample_name\tsample_type\tinput_path\tdownsampled_pickle_path\toriginal_aligned_read_ct\tdownsampled_read_ct\n')
    log_file.write(header)
            
    file = open(args.experiment_object,'rb')
    experiment_object = pickle.load(file)
    file.close()
    
    run_depth = {}
    
    #calculate minimum sample per type
    for sample_type in experiment_object:
        for sample_name in experiment_object[sample_type]:
            for replicate in experiment_object[sample_type][sample_name]:
                print(sample_type, sample_name, replicate)
                aligned_read_ct = experiment_object[sample_type][sample_name][replicate]['aligned_read_ct']
                print(aligned_read_ct)
            
            if sample_type not in run_depth:
                run_depth[sample_type] = aligned_read_ct
                print(aligned_read_ct)
                
            run_depth[sample_type] = min([run_depth[sample_type], aligned_read_ct]) 
    
    pickle_name = ('run_depth.p')
    pickle.dump(run_depth, open(pickle_name, 'wb'))
    #pull 
    for sample_type in experiment_object:
        for sample_name in experiment_object[sample_type]:
            for replicate in experiment_object[sample_type][sample_name]:
                output_path = experiment_object[sample_type][sample_name][replicate]['output_path']
                
                sample_depth = experiment_object[sample_type][sample_name][replicate]['aligned_read_ct']
                min_depth = run_depth[sample_type]
                                
                uid = experiment_object[sample_type][sample_name][replicate]['uid']
                
                prefix = ('{}{}').format(output_path, uid)
                #output = ('{}{}').format(output_path, uid)
                            
                #if sample_depth > min_depth:
                print(sample_depth)
                downsample_frequency = min_depth/sample_depth
                
                experiment_object[sample_type][sample_name][replicate]['downsample_frequency'] = downsample_frequency
                
                print('downsampling, ', sample_name, downsample_frequency)
                
                normalized_locus_name, normalized_locus_uid_name = normalize_reads(prefix, prefix, downsample_frequency)
                
                experiment_object[sample_type][sample_name][replicate]['normalized_locus'] = normalized_locus_name
                
                experiment_object[sample_type][sample_name][replicate]['normalized_locus_uid'] = normalized_locus_uid_name

                outline = ('{sample_name}\t{sample_type}\t{input_path}\t{normed_pickle}\t{aligned_read_ct}\n').format(
                    sample_name = sample_name, sample_type = sample_type, 
                    input_path = prefix, normed_pickle = normalized_locus_name,
                    aligned_read_ct = aligned_read_ct)
                
                log_file.write(outline)
                
    #update experimental_object
    pickle_name = ('{}').format(args.experiment_object)
    pickle.dump(experiment_object, open(pickle_name, 'wb'))
    
    '''
    test stuff     
    file = open('RPF_DGY1743_R2_unnormalized_locus_depth.p','rb')
    temp_pickle = pickle.load(file)
    file.close()
    
    temp_pickle['XI']['+'][515005]
            
    RPF_DGY1743_R2_read_to_locus.p
            
    file = open('RPF_DGY1743_R2_read_to_locus.p','rb')
    read_to_locus = pickle.load(file)
    file.close()
    '''
    
def plot_across_strains():
    #for readtype in ['RPF_ratio']:
    for readtype in ['DNA_ratio', 'RPF_ratio', 'RNA_ratio', 'tEff_ratio']:
        outfile_name = ('{}{}_mORF_sig_plot.pdf').format('pres2', readtype)
        
        strain_set = ['DGY1657_v_DGY1726','DGY1657_v_DGY1728','DGY1657_v_DGY1735', 'DGY1657_v_DGY1741', 'DGY1657_v_DGY1743']
        strain_set = strain_set[::-1]
        
        if readtype == 'DNA_ratio':
            zmin = 0
            zmax = 4
            color_scale = [[0, 'rgb(0,0,255)'], [(1/4), 'rgb(255,255,255)'], [1, 'rgb(255,0,0)']]
        else:
            zmin = 0
            zmax = 4
            color_scale = [[0, 'rgb(0,0,255)'], [(1/4), 'rgb(255,255,255)'], [1, 'rgb(255,0,0)']]
               
        zd=[]
        xd=[]
        yd=[]
        ct_list = []
        
        for gene in gene_list:
            #print(gene)
            yd.append(gene)
            zsub = []
            for strain in strain_set:
                if strain not in xd:
                    xd.append(strain)
                    
                count = (plot_dict[gene][strain][readtype])
                print(gene, strain, readtype, count)
                
                if count == 0:
                    count = 1
                    
                if count == None:
                    zsub.append(count)
                    
                else:
                    t_ct = (count)
                    #t_ct = np.log2(count)
                    zsub.append(t_ct)
                    ct_list.append(t_ct)
                                        
            zd.append(zsub)
            
#        print(len(ct_list))
#        ismin = min(ct_list)
#        ismedian = np.median(ct_list)
#        isstd = np.std(ct_list)
#        ismax = ismedian+isstd
        
#        print('median', ismedian)
#        print('std', isstd)
        
        fig = go.Figure(data=go.Heatmap(
                           z=zd,
                           x=xd,
                           y=yd,
                           # TODO: allow for setup of mins and maxes by argument
                           zmin = zmin,
                           zmax = zmax,
                           hoverongaps = False,
                           colorscale=color_scale
                           ),
            )
        
        fig.update_layout(
        autosize=False,
        width=1500,
        height=3500,
        margin=dict(
            l=50,
            r=50,
            b=100,
            t=100,
            pad=4
        ),)
        
        fig.show()

        fig.write_image(outfile_name)
    
if args.plot:
    import plotly.graph_objects as go
    sig_filter = True
    
    plot_dict = {}
    gene_set = set()
    strain_set = set()
    #file_list_list = [['mORF_rel_CNV_1728v1657.tab','mORF_rel_CNV_1728v1657_sig.tab']]
    #,
    #                  ['TLS_rel_CNV_1728v1657.tab','TLS_rel_CNV_1728v1657_sig.tab']]
    
    #file_list = ['mORF_rel_CNV_1728v1657.tab', 'mORF_rel_CNV_1726v1657.tab', 
    #'mORF_rel_CNV_1743v1657.tab', 'mORF_rel_CNV_1735v1657.tab', 'mORF_rel_CNV_1741v1657.tab']
#    file_list_list = [['TLS_rel_CNV_1728v1657_sig.tab', 'TLS_rel_CNV_1726v1657_sig.tab', 
#'TLS_rel_CNV_1743v1657_sig.tab','TLS_rel_CNV_1735v1657_sig.tab', 'TLS_rel_CNV_1741v1657_sig.tab'],
#                      ['TLS_rel_CNV_1728v1657.tab', 'TLS_rel_CNV_1726v1657.tab', 
#'TLS_rel_CNV_1743v1657.tab','TLS_rel_CNV_1735v1657.tab', 'TLS_rel_CNV_1741v1657.tab']]
#    
#    file_list_list = [['mORF_rel_CNV_1728v1657.tab', 'mORF_rel_CNV_1726v1657.tab', 
#                       'mORF_rel_CNV_1743v1657.tab', 'mORF_rel_CNV_1735v1657.tab', 'mORF_rel_CNV_1741v1657.tab'],
#                      ['mORF_rel_CNV_1728v1657_sig.tab', 'mORF_rel_CNV_1726v1657_sig.tab', 
#                       'mORF_rel_CNV_1743v1657_sig.tab','mORF_rel_CNV_1735v1657_sig.tab', 'mORF_rel_CNV_1741v1657_sig.tab']]
#    
    file_name = ("C:/Gresham/Project_Carolino/supplemental/None_normalized_all_calls_2.log")

#    for file_list in file_list_list:    
#        for filename in file_list:
#            filepath = ('{}').format(filename)
#            #filepath = ('{}{}').format(args.output_file, filename)
#            #infile = open(file)
#            #filename = file
    infile = open(file_name)
    #print('plotting...', filepath)
    
    for line in infile:
        #if 'gene' not in line:
            
        #if line[0] == 'Y':
        if line[0:2]=='YK':
            line = line.strip()
            gene = line.split('\t')[0]
#                print(gene)
#                print(line)
                        
            if gene not in plot_dict:
                plot_dict[gene] = {}
                
            process = True
            if sig_filter:
                process = max([line.split('\t')[30], line.split('\t')[31], line.split('\t')[32]])
            
            if process:
                DNA_ratio = round(float(line.split('\t')[3]),0)
                '''
                <Fuck make better, perform calculation earlier>
                '''
                anc_rpf_exp = (float(line.split('\t')[8])+float(line.split('\t')[9]))*DNA_ratio
                evo_rpf_obs = (float(line.split('\t')[4])+float(line.split('\t')[5]))
                
                RPF_eff = evo_rpf_obs/max(anc_rpf_exp,1)
                '''
                </Fuck make better, perform calculation earlier>
                '''
                RNA_eff = float(line.split('\t')[27])
                tEff_eff = float(line.split('\t')[29])
                            
                strain = line.split('\t')[33]
                
                plot_dict[gene][strain]={'DNA_ratio': DNA_ratio, 'RPF_ratio':RPF_eff, 'RNA_ratio':RNA_eff, 'tEff_ratio':tEff_eff}
                
                strain_set.add(strain)

                    
    for gene in plot_dict:            
        if strain not in plot_dict[gene]:
            plot_dict[gene][strain] = {'DNA_ratio':None, 'RPF_ratio':None, 'RNA_ratio':None, 'tEff_ratio':None}
                
    gene_list = list(set(list(plot_dict.keys())))
    gene_list.sort(reverse=True)
    #print('length of gene list', len(gene_list))
    
    plot_across_strains()
                
    

                
#if False:
#    calculate_expression_profile_old
#    
#    #TODO load DNA depth ::: pickles contain
#    if args.relative_depth_file:
#        dna_depth = True
#        # held out ,
#        strain_list = ['DGY1657', 'DGY1726', 'DGY1728', 'DGY1735', 'DGY1741', 'DGY1743']
#        #strain_list = ['DGY1657', 'DGY1728']
#        
#        for strain in strain_list:
#            file_name = ('depth\{}_abs_depth.p').format(strain, args.relative_depth_file)
#            print('loading DNA depths for ', strain, ' ', file_name)
#            file = open(file_name,'rb')
#            temp_pickle = pickle.load(file)
#            file.close()
#            
#            relative_depth_dict[strain] = temp_pickle
#            
#    readtype_list = ['RNA','RPF']
#    strain_list = ['DGY1657', 'DGY1726', 'DGY1728', 'DGY1735', 'DGY1741', 'DGY1743']
#    #strain_list = ['DGY1657', 'DGY1728']
#    replicate_list = ['R1', 'R2']
#    site_list = ['TLS', 'threeUTR', 'mORF']
#    suffix = 'density.tab'
#    
#    for readtype in readtype_list:
#        for strain in strain_list:
#            for replicate in replicate_list:
#                for site in site_list:
#                    #if strain == 'DGY1657':
#                        #print(readtype, strain, replicate, site, suffix)
#                    # adds to density_dict and coord_dict
#                    parse_density_file(readtype, strain, replicate, site, suffix)
#    
#    for strain in strain_list:
#        for replicate in replicate_list:
#            for site in site_list:        
#                add_teff(strain, replicate, site)
#    
#    cnv_list_1728 = []
#    for gene in density_dict:
#        if gene[:2] == 'YK':
#           cnv_list_1728.append(gene) 
#    
#    #TODO - make a better data input method
#    other_list = [x for x in list(density_dict.keys()) if x not in cnv_list_1728]
#    #cnv_list_1726 = ['YER129W','YER130C','YER131W','YER132C','YER133W','YER134C','YER135C','YER136W','YER137C']
#    #cnv_list_1726 =['YKR010C','YKR011C','YKR012C','YKR013W','YKR014C','YKR015C',
#    #'YKR016W','YKR017C','YKR018C','YKR019C','YKR020W','YKR021W','YKR022C','YKR023W',
#    #'YKR024C','YKR025W','YKR026C','YKR027W','YKR028W','YKR029C','YKR030W','YKR031C',
#    #'YKR033C','YKR034W','YKR035W-A','YKR036C','YKR037C','YKR038C','YKR039W','YKR040C',
#    #'YKR041W','YKR042W','YKR043C','YKR044W','YKR045C','YKR046C','YKR047W','YKR048C',
#    #'YKR049C','YKR050W','YKR051W','YKR052C','YKR053C','YKR054C','YKR055W','YKR056W',
#    #'YKR057W','YKR058W','YKR059W','YKR060W','YKR061W','YKR062W','YKR063C','YKR064W',
#    #'YKR065C','YKR066C','YKR067W','YKR068C','YKR069W','YKR070W','YKR071C','YKR072C',
#    #'YKR074W','YKR075C','YKR075W-A','YKR076W','YKR077W','YKR078W','YKR079C','YKR080W',
#    #'YKR081C','YKR082W','YKR083C','YKR084C','YKR085C','YKR086W','YKR087C','YKR088C',
#    #'YKR089C','YKR090W','YKR091W','YKR092C','YKR093W','YKR094C','YKR095W','YKR095W-A','YKR096W','YKR097W']
#    eval_gene_by_gene(cnv_list_1728, 'DGY1726', 'DGY1657', 'rel_CNV_1726v1657.tab')
#    
#    eval_gene_by_gene(cnv_list_1728, 'DGY1728', 'DGY1657', 'rel_CNV_1728v1657.tab')
#    
#    #cnv_list_1735 = ['YKR021W','YKR022C','YKR023W','YKR024C','YKR025W','YKR026C',
#    #'YKR027W','YKR028W','YKR029C','YKR030W','YKR031C','YKR032W','YKR033C','YKR034W',
#    #'YKR035C','YKR035W-A','YKR036C','YKR037C','YKR038C','YKR039W','YKR040C','YKR041W',
#    #'YKR042W','YKR043C','YKR044W','YKR045C','YKR046C','YKR047W','YKR048C','YKR049C',
#    #'YKR050W','YKR051W','YKR052C','YKR053C','YKR054C','YKR055W','YKR056W','YKR057W',
#    #'YKR058W','YKR059W','YKR060W','YKR061W','YKR062W','YKR063C','YKR064W','YKR065C',
#    #'YKR066C','YKR067W','YKR068C','YKR069W','YKR070W','YKR071C','YKR072C','YKR073C',
#    #'YKR074W','YKR075C','YKR075W-A','YKR076W','YKR077W','YKR078W','YKR079C','YKR080W',
#    #'YKR081C','YKR082W','YKR083C','YKR084C','YKR085C','YKR086W','YKR087C','YKR088C',
#    #'YKR089C','YKR090W','YKR091W','YKR092C','YKR093W','YKR094C','YKR095W','YKR095W-A',
#    #'YKR096W','YKR097W','YKR098C','YKR099W','YKR100C','YKR101W']
#    eval_gene_by_gene(cnv_list_1728, 'DGY1735', 'DGY1657', 'rel_CNV_1735v1657.tab')
#    
#    #cnv_list_1741 = ['YKR029C','YKR030W','YKR031C','YKR032W','YKR033C','YKR034W',
#    #'YKR035C','YKR035W-A','YKR036C','YKR037C','YKR038C','YKR039W','YKR040C','YKR041W',
#    #'YKR042W','YKR043C','YKR044W','YKR045C','YKR046C','YKR047W','YKR048C','YKR049C','YKR050W']
#    eval_gene_by_gene(cnv_list_1728, 'DGY1741', 'DGY1657', 'rel_CNV_1741v1657.tab')
#    
#    #cnv_list_1743 = ['YKR001C','YKR002W','YKR003W','YKR004C','YKR005C','YKR006C',
#    #'YKR007W','YKR008W','YKR009C','YKR010C','YKR011C','YKR012C','YKR013W','YKR014C',
#    #'YKR015C','YKR016W','YKR017C','YKR018C','YKR019C','YKR020W','YKR021W','YKR022C',
#    #'YKR023W','YKR024C','YKR025W','YKR026C','YKR027W','YKR028W','YKR029C','YKR030W',
#    #'YKR031C','YKR032W','YKR033C','YKR034W','YKR035C','YKR035W-A','YKR036C','YKR037C',
#    #'YKR038C','YKR039W','YKR040C','YKR041W','YKR042W','YKR043C','YKR044W','YKR045C',
#    #'YKR046C','YKR047W','YKR048C','YKR049C','YKR050W','YKR051W','YKR052C','YKR053C',
#    #'YKR054C','YKR055W','YKR056W','YKR057W','YKR058W','YKR059W','YKR060W','YKR061W',
#    #'YKR062W','YKR063C','YKR064W','YKR065C','YKR066C','YKR067W','YKR068C','YKR069W',
#    #'YKR070W','YKR071C','YKR072C','YKR073C','YKR074W','YKR075C','YKR075W-A','YKR076W',
#    #'YKR077W','YKR078W','YKR079C','YKR080W','YKR081C','YKR082W','YKR083C','YKR084C',
#    #'YKR085C','YKR086W','YKR087C','YKR088C','YKR089C','YKR090W','YKR091W','YKR092C',
#    #'YKR093W','YKR094C','YKR095W','YKR095W-A','YKR096W'] 
#    eval_gene_by_gene(cnv_list_1728, 'DGY1743', 'DGY1657', 'rel_CNV_1743v1657.tab')
#    
#    eval_gene_by_gene(other_list, 'DGY1726', 'DGY1657', 'rel_CNN_1726v1657.tab')
#    
#    #other_list_1728 = [x for x in list(density_dict.keys()) if x not in cnv_list_1728]
#    eval_gene_by_gene(other_list, 'DGY1728', 'DGY1657', 'rel_CNN_1728v1657.tab')
#    
#    #other_list_1735 = [x for x in list(density_dict.keys()) if x not in cnv_list_1728]
#    eval_gene_by_gene(other_list, 'DGY1735', 'DGY1657', 'rel_CNN_1735v1657.tab')
#    
#    #other_list_1741 = [x for x in list(density_dict.keys()) if x not in cnv_list_1741]
#    eval_gene_by_gene(other_list, 'DGY1741', 'DGY1657', 'rel_CNN_1741v1657.tab')
#    
#    #other_list_1743 = [x for x in list(density_dict.keys()) if x not in cnv_list_1743]
#    eval_gene_by_gene(other_list, 'DGY1743', 'DGY1657', 'rel_CNN_1743v1657.tab')
#    
#    import plotly.graph_objects as go
#    
#    plot_dict = {}
#    gene_set = set()
#    #file_list_list = [['mORF_rel_CNV_1728v1657.tab','mORF_rel_CNV_1728v1657_sig.tab']]
#    #,
#    #                  ['TLS_rel_CNV_1728v1657.tab','TLS_rel_CNV_1728v1657_sig.tab']]
#    
#    #file_list = ['mORF_rel_CNV_1728v1657.tab', 'mORF_rel_CNV_1726v1657.tab', 
#    #'mORF_rel_CNV_1743v1657.tab', 'mORF_rel_CNV_1735v1657.tab', 'mORF_rel_CNV_1741v1657.tab']
##    file_list_list = [['TLS_rel_CNV_1728v1657_sig.tab', 'TLS_rel_CNV_1726v1657_sig.tab', 
##'TLS_rel_CNV_1743v1657_sig.tab','TLS_rel_CNV_1735v1657_sig.tab', 'TLS_rel_CNV_1741v1657_sig.tab'],
##                      ['TLS_rel_CNV_1728v1657.tab', 'TLS_rel_CNV_1726v1657.tab', 
##'TLS_rel_CNV_1743v1657.tab','TLS_rel_CNV_1735v1657.tab', 'TLS_rel_CNV_1741v1657.tab']]
##    
#    file_list_list = [['mORF_rel_CNV_1728v1657.tab', 'mORF_rel_CNV_1726v1657.tab', 
#                       'mORF_rel_CNV_1743v1657.tab', 'mORF_rel_CNV_1735v1657.tab', 'mORF_rel_CNV_1741v1657.tab'],
#                      ['mORF_rel_CNV_1728v1657_sig.tab', 'mORF_rel_CNV_1726v1657_sig.tab', 
#                       'mORF_rel_CNV_1743v1657_sig.tab','mORF_rel_CNV_1735v1657_sig.tab', 'mORF_rel_CNV_1741v1657_sig.tab']]
#    
#    for file_list in file_list_list:    
#        for filename in file_list:
#            filepath = ('{}').format(filename)
#            #filepath = ('{}{}').format(args.output_file, filename)
#            #infile = open(file)
#            #filename = file
#            infile = open(filepath)
#            print('plotting...', filepath)
#            
#            for line in infile:
#                #if line[0] == 'Y':
#                if line[0:3]=='YKR':
#                    gene = line.split('\t')[0]
#    #                print(gene)
#    #                print(line)
#                    
#                    if gene not in plot_dict:
#                        plot_dict[gene] = {}
#                        
#                    DNA_ratio = float(line.split('\t')[1])   
#                    RPF_eff = float(line.split('\t')[23])
#                    RNA_eff = float(line.split('\t')[25])
#                    tEff_eff = float(line.split('\t')[27])
#                    
#                    plot_dict[gene][filename]={'DNA_ratio': DNA_ratio, 'RPF_ratio':RPF_eff, 'RNA_ratio':RNA_eff, 'tEff_ratio':tEff_eff}
#        
#        for gene in plot_dict:            
#            for filename in file_list:
#                if filename not in plot_dict[gene]:
#                    plot_dict[gene][filename] = {'DNA_ratio':None, 'RPF_ratio':None, 'RNA_ratio':None, 'tEff_ratio':None}
#                    
#        gene_list = list(set(list(plot_dict.keys())))
#        gene_list.sort(reverse=True)
#        print('length of gene list', len(gene_list))
#                    
#        for readtype in ['DNA_ratio', 'RPF_ratio', 'RNA_ratio', 'tEff_ratio']:
#            #outfile_name = ('{}{}_mORF_plot.pdf').format('temp', readtype)
#            
##            if 'sig' in filename:
##                outfile_name = ('{}_TLS_plot_siglog.pdf').format(readtype)
##            else:
##                outfile_name = ('{}_TLS_plotlog.pdf').format(readtype)
#            
#            if 'sig' in filename:
#                outfile_name = ('{}_mORF_plot_sig.pdf').format(readtype)
#            else:
#                outfile_name = ('{}_mORF_plot.pdf').format(readtype)
#                
#            #outfile_name = ('{}{}_mORF_plot.pdf').format(args.output_file, readtype)
#            #outfile_name = ('{}{}_TLS_plot.pdf').format(args.output_file, readtype)
#                   
#            zd=[]
#            xd=[]
#            yd=[]
#            ct_list = []
#            
#            for gene in gene_list:
#                print(gene)
#                yd.append(gene)
#                zsub = []
#                for filename in file_list:
#                    if filename not in xd:
#                        xd.append(filename)
#                        
#                    count = (plot_dict[gene][filename][readtype])
#                    if count == 0:
#                        count = 1
#                    if count == None:
#                        zsub.append(count)
#                        
#                    else:
#                        #t_ct = (count)
#                        t_ct = np.log2(count)
#                        zsub.append(t_ct)
#                        ct_list.append(t_ct)
#                                            
#                zd.append(zsub)
#                
#            print(len(ct_list))
#            ismin = min(ct_list)
#            ismedian = np.median(ct_list)
#            isstd = np.std(ct_list)
#            ismax = ismedian+isstd
#            
#    #        print('median', ismedian)
#    #        print('std', isstd)
#            
#            fig = go.Figure(data=go.Heatmap(
#                               z=zd,
#                               x=xd,
#                               y=yd,
#                               # TODO: allow for setup of mins and maxes by argument
#                               zmin = -2,
#                               zmax = 2,
#                               hoverongaps = False,
#                               colorscale=[[0, 'rgb(0,0,255)'], [0.5, 'rgb(255,255,255)'], [1, 'rgb(255,0,0)']]
#                               ),
#                )
#            
#            fig.update_layout(
#            autosize=False,
#            width=1500,
#            height=3500,
#            margin=dict(
#                l=50,
#                r=50,
#                b=100,
#                t=100,
#                pad=4
#            ),)
#            
#            fig.show()
#
#            fig.write_image(outfile_name)
#        
        
if args.manual_depth:
    infile = open(args.input_depth_file)
    outfile = open(args.output_file, 'w')
    
    header = ('### Notice - this is a simulated depth file generated by multiplying all of chromo XI by 2 using DGY1657 as base')
    outfile.write(header)
    
    for line in infile:
        #NC_001133.9	1	30
        chromo, nt, depth = line.split('\t')
        
        if chromo == "NC_001143.9" or chromo == 'XI':
            outline = ('{}\t{}\t{}\n').format(chromo, nt, int(depth) * 2)
            outfile.write(outline)
            
        else:
            outfile.write(line)
            
    infile.close()
    outfile.close()

def test_overlap(lchromo, lstart, lstop, tchromo, tstart, tstop):
    if lchromo == tchromo:
        
        if (lstart <= tstart) and (lstop >= tstart):
            return(True)
            
        if (lstart <= tstop) and (lstop >= tstop):
            return(True)
            
        if (lstart >= tstart) and (lstop <= tstop):
            return(True)
        
    return(False)
    
if False:
    import numpy as np
    target = ('XI:479636-641520')
    
    
    tchromo = target.split(':')[0]
    tstart = int(target.split(':')[1].split('-')[0])
    tstop = int(target.split(':')[1].split('-')[1])
    
    exp = 3
    
    depth_dict = {}
    filename = ('RPF_DGY1657_R1_tEff.bedgraph')
    #filename = ('RNA_DGY1735_R1.bedgraph')
    infile = open(filename)
    
    for line in infile:
        lchromo = line.split('\t')[0]
        lstart = int(line.split('\t')[1])
        lstop = int(line.split('\t')[2])
        lval = float(line.split('\t')[3])
        
        if lchromo not in depth_dict:
            depth_dict[lchromo] = {}
                        
        if test_overlap(lchromo, lstart, lstop, tchromo, tstart, tstop):
            correction = exp
        else:
            correction = 1
            
        for nt in range(lstart, lstop +1):
            depth_dict[lchromo][nt] = lval*correction
    
    infile.close()

    #filename = ('RPF_DGY1735_R1.bedgraph')
    filename = ('RPF_DGY1657_R1_tEff.bedgraph')
    outfile_name = (filename.split('.')[0]+'_tEff.bedgraph')
    
    outfile = open(outfile_name, 'w')
    
    infile = open(filename)
    
    for line in infile:
        line = line.strip()
        lchromo = line.split('\t')[0]
        lstart = int(line.split('\t')[1])
        lstop = int(line.split('\t')[2])
        val = float(line.split('\t')[3])
            
        for nt in range(lstart, lstop +1):
            if nt in depth_dict[lchromo]:
                nval = np.log10(val / (max(depth_dict[lchromo][nt], 1)))
            else:
                nval = np.log10(val)
                
            outline = ("{}\t{}\t{}\t{}\n").format(lchromo, nt, nt+1, nval)
            outfile.write(outline)
            
    infile.close()
    outfile.close()
            
if False:
    import random
    rando_dict = {}
    filename = ('DGY1657.bedgraph')
    #filename = ('RNA_DGY1735_R1.bedgraph')
    infile = open(filename)
    
    outfile_name = (filename.split('.')[0]+'_rando.bedgraph')
    
    outfile = open(outfile_name, 'w')
    
    for line in infile:
        lchromo = line.split('\t')[0]
        
        if lchromo == 'II':
            line = line.strip()
            lstart = int(line.split('\t')[1])
            lstop = int(line.split('\t')[2])
            val = float(line.split('\t')[3])
            
            for nt in range(lstart, lstop +1):
                if nt < 666000:
                    rando_dict[nt]=val
                
    infile.close()
    
    random_list = []            
    for rand_nt in random.sample(list(rando_dict.keys()),len(rando_dict)):
        random_list.append(rand_nt)
        
    max_nt = max(random_list)
    i = 0
    for target_nt in range(0, max_nt):
        outline = ("{}\t{}\t{}\t{}\n").format('XI', target_nt, target_nt+1, rando_dict[target_nt])
        outfile.write(outline)
        i+=1
        
    outfile.close()
    
    
